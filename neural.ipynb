{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acfb164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_model.py - Part 1: Core Functions and Model Loading\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "\n",
    "# Suppress Matplotlib warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "## -----------------------------------------------------------\n",
    "## UTILITY FUNCTIONS FOR MODEL OUTPUT HANDLING\n",
    "## -----------------------------------------------------------\n",
    "\n",
    "def get_model_output(model, input_tensor, return_embeddings=False):\n",
    "    \"\"\"\n",
    "    Safely handle model outputs that may return tuples or single tensors.\n",
    "    Compatible with delta analysis models that return (output, embeddings).\n",
    "    \"\"\"\n",
    "    model_output = model(input_tensor)\n",
    "    \n",
    "    if isinstance(model_output, tuple):\n",
    "        output, embeddings = model_output\n",
    "        if return_embeddings:\n",
    "            return output, embeddings\n",
    "        else:\n",
    "            return output\n",
    "    else:\n",
    "        # Single tensor output\n",
    "        if return_embeddings:\n",
    "            return model_output, None\n",
    "        else:\n",
    "            return model_output\n",
    "\n",
    "## -----------------------------------------------------------\n",
    "## SECURE MODEL LOADING\n",
    "## -----------------------------------------------------------\n",
    "\n",
    "def load_model(model_path, model_class, device=None):\n",
    "    \"\"\"\n",
    "    Securely loads the model from the .pth file.\n",
    "    \n",
    "    SECURITY FIXES:\n",
    "    1. Uses weights_only=True to prevent arbitrary code execution\n",
    "    2. Adds device mapping for cross-device compatibility\n",
    "    3. Adds error handling for corrupted files\n",
    "    4. Validates file exists before loading\n",
    "    \"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file '{model_path}' not found.\")\n",
    "    \n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    try:\n",
    "        # Create model instance first\n",
    "        model = model_class()\n",
    "        \n",
    "        # SECURITY FIX: Use weights_only=True to prevent pickle vulnerabilities\n",
    "        # Map to CPU first to avoid device issues\n",
    "        state_dict = torch.load(model_path, map_location='cpu', weights_only=True)\n",
    "        \n",
    "        # Load the state dict\n",
    "        model.load_state_dict(state_dict)\n",
    "        \n",
    "        # Move to target device\n",
    "        model = model.to(device)\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        \n",
    "        print(f\"Model loaded successfully on device: {device}\")\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        print(\"This could be due to:\")\n",
    "        print(\"1. Architecture mismatch between saved model and model_class\")\n",
    "        print(\"2. Corrupted model file\")\n",
    "        print(\"3. Version incompatibility\")\n",
    "        raise\n",
    "\n",
    "## -----------------------------------------------------------\n",
    "## ANALYSIS FUNCTIONS\n",
    "## -----------------------------------------------------------\n",
    "\n",
    "def analyze_architecture(model, input_size):\n",
    "    \"\"\"Prints the model summary using torchsummary.\"\"\"\n",
    "    print(\"\\n### 1. Model Architecture Summary ###\")\n",
    "    print(\"This shows the layers, output shapes, and parameter counts.\")\n",
    "    try:\n",
    "        if isinstance(input_size, tuple):\n",
    "            summary(model, input_size=input_size)\n",
    "        else:\n",
    "            summary(model, input_size=(input_size,))\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate summary. Error: {e}\")\n",
    "        print(\"Printing model structure instead:\")\n",
    "        print(\"-\" * 50)\n",
    "        for name, module in model.named_modules():\n",
    "            if name:  # Skip the root module\n",
    "                print(f\"{name}: {module}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "def analyze_weights(model):\n",
    "    \"\"\"Visualizes the distribution of weights and biases for each layer.\"\"\"\n",
    "    print(\"\\n### 2. Weight and Bias Distribution ###\")\n",
    "    print(\"This helps identify issues like vanishing or exploding gradients.\")\n",
    "    \n",
    "    params_list = list(model.named_parameters())\n",
    "    if not params_list:\n",
    "        print(\"No parameters found in the model.\")\n",
    "        return\n",
    "    \n",
    "    num_params = len(params_list)\n",
    "    \n",
    "    if num_params == 1:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "        axes = [ax]\n",
    "    else:\n",
    "        fig, axes = plt.subplots(num_params, 1, figsize=(8, 2 * num_params))\n",
    "        if num_params == 1:\n",
    "            axes = [axes]\n",
    "    \n",
    "    fig.suptitle('Weight and Bias Distributions per Layer')\n",
    "    \n",
    "    for i, (name, param) in enumerate(params_list):\n",
    "        if param.requires_grad and param.numel() > 0:\n",
    "            ax = axes[i]\n",
    "            param_data = param.data.cpu().numpy().flatten()\n",
    "            \n",
    "            if np.all(param_data == param_data[0]):\n",
    "                ax.text(0.5, 0.5, f\"All values = {param_data[0]:.4f}\", \n",
    "                       transform=ax.transAxes, ha='center', va='center')\n",
    "                ax.set_title(name)\n",
    "            else:\n",
    "                ax.hist(param_data, bins=min(100, len(param_data)), alpha=0.7)\n",
    "                ax.set_title(f\"{name} (mean: {param_data.mean():.4f}, std: {param_data.std():.4f})\")\n",
    "        else:\n",
    "            axes[i].text(0.5, 0.5, \"No gradients or empty tensor\", \n",
    "                        transform=axes[i].transAxes, ha='center', va='center')\n",
    "            axes[i].set_title(name)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "def analyze_feature_maps(model, layer_name, input_tensor):\n",
    "    \"\"\"Visualizes the feature maps (activations) of a specific convolutional layer.\"\"\"\n",
    "    print(f\"\\n### 3. Feature Map Visualization (Layer: {layer_name}) ###\")\n",
    "    print(\"This shows what features the model detects at an intermediate stage.\")\n",
    "    \n",
    "    activations = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activations[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    try:\n",
    "        available_layers = dict(model.named_modules())\n",
    "        if layer_name not in available_layers:\n",
    "            print(f\"Error: Layer '{layer_name}' not found.\")\n",
    "            print(f\"Available layers: {list(available_layers.keys())}\")\n",
    "            return\n",
    "\n",
    "        target_layer = available_layers[layer_name]\n",
    "        handle = target_layer.register_forward_hook(get_activation(layer_name))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _ = get_model_output(model, input_tensor)  # Use our utility function\n",
    "        handle.remove()\n",
    "\n",
    "        if layer_name not in activations:\n",
    "            print(f\"No activations captured for layer '{layer_name}'\")\n",
    "            return\n",
    "\n",
    "        acts = activations[layer_name].squeeze()\n",
    "        \n",
    "        if acts.dim() == 1:\n",
    "            print(f\"Layer '{layer_name}' produces 1D output, cannot visualize as feature maps.\")\n",
    "            return\n",
    "        elif acts.dim() == 2:\n",
    "            acts = acts.unsqueeze(0)\n",
    "        elif acts.dim() > 3:\n",
    "            print(f\"Layer '{layer_name}' produces {acts.dim()}D output, taking first sample.\")\n",
    "            acts = acts[0] if acts.dim() == 4 else acts\n",
    "            \n",
    "        num_maps = acts.size(0) if acts.dim() >= 3 else 1\n",
    "        cols = min(8, num_maps)\n",
    "        rows = (num_maps + cols - 1) // cols\n",
    "        \n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(2 * cols, 2 * rows))\n",
    "        fig.suptitle(f'Feature Maps from Layer: {layer_name}')\n",
    "        \n",
    "        if num_maps == 1:\n",
    "            axes = [axes]\n",
    "        elif rows == 1:\n",
    "            axes = axes if hasattr(axes, '__len__') else [axes]\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "            \n",
    "        for i in range(rows * cols):\n",
    "            ax = axes[i] if hasattr(axes, '__len__') else axes\n",
    "            if i < num_maps:\n",
    "                if acts.dim() == 3:\n",
    "                    img = acts[i].cpu().numpy()\n",
    "                else:\n",
    "                    img = acts.cpu().numpy()\n",
    "                ax.imshow(img, cmap='viridis')\n",
    "                ax.set_title(f'Map {i+1}', fontsize=8)\n",
    "            else:\n",
    "                ax.set_visible(False)\n",
    "            ax.axis('off')\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not visualize feature maps. Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def analyze_saliency(model, input_tensor):\n",
    "    \"\"\"Generates a saliency map to show which input pixels are most influential.\"\"\"\n",
    "    print(\"\\n### 4. Saliency Maps ###\")\n",
    "    print(\"This highlights the pixels your model 'looks at' for its prediction.\")\n",
    "\n",
    "    input_tensor = input_tensor.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    try:\n",
    "        output = get_model_output(model, input_tensor)  # Use our utility function\n",
    "        \n",
    "        if output.dim() == 1:\n",
    "            output_idx = output.argmax()\n",
    "        else:\n",
    "            output_idx = output.argmax(dim=1)\n",
    "        \n",
    "        output_max = output.flatten()[output_idx] if output.dim() > 1 else output[output_idx]\n",
    "        \n",
    "        model.zero_grad()\n",
    "        if input_tensor.grad is not None:\n",
    "            input_tensor.grad.zero_()\n",
    "            \n",
    "        output_max.backward()\n",
    "        \n",
    "        if input_tensor.grad is None:\n",
    "            print(\"No gradients computed. Make sure the model supports gradient computation.\")\n",
    "            return\n",
    "        \n",
    "        saliency, _ = torch.max(input_tensor.grad.data.abs(), dim=1)\n",
    "        saliency = saliency.squeeze()\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(input_tensor.detach().squeeze().numpy(), cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(saliency.cpu().numpy(), cmap='hot')\n",
    "        plt.title('Saliency Map')\n",
    "        plt.axis('off')\n",
    "        plt.suptitle('Saliency Map Analysis')\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate saliency map. Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin-ai1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
