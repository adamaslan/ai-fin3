{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Processed DataFrame (first 5 rows from fetched month):\n",
      "                     Real Upper Band  Real Middle Band  Real Lower Band\n",
      "2024-05-01 05:35:00         168.9581          168.6132         168.2682\n",
      "2024-05-01 05:40:00         168.9551          168.5948         168.2344\n",
      "2024-05-01 05:45:00         168.8601          168.5704         168.2808\n",
      "2024-05-01 05:50:00         168.8290          168.5580         168.2870\n",
      "2024-05-01 05:55:00         168.8050          168.5491         168.2931\n",
      "\n",
      "Data for 2024-05-19 and 2024-05-20:\n",
      "                     Real Upper Band  Real Middle Band  Real Lower Band\n",
      "2024-05-20 04:00:00         189.2216          189.1166         189.0117\n",
      "2024-05-20 04:05:00         189.2217          189.1122         189.0027\n",
      "2024-05-20 04:10:00         189.2217          189.1122         189.0027\n",
      "2024-05-20 04:15:00         189.2366          189.1171         188.9977\n",
      "2024-05-20 04:20:00         189.2547          189.1236         188.9926\n",
      "...                              ...               ...              ...\n",
      "2024-05-20 19:35:00         190.4347          190.3176         190.2005\n",
      "2024-05-20 19:40:00         190.4373          190.3196         190.2020\n",
      "2024-05-20 19:45:00         190.4344          190.3181         190.2019\n",
      "2024-05-20 19:50:00         190.4258          190.3156         190.2055\n",
      "2024-05-20 19:55:00         190.4175          190.3129         190.2083\n",
      "\n",
      "[192 rows x 3 columns]\n",
      "\n",
      "Filtered DataFrame for Autoencoder analysis (first 5 rows):\n",
      "                     Real Upper Band  Real Middle Band  Real Lower Band\n",
      "2024-05-20 04:00:00         189.2216          189.1166         189.0117\n",
      "2024-05-20 04:05:00         189.2217          189.1122         189.0027\n",
      "2024-05-20 04:10:00         189.2217          189.1122         189.0027\n",
      "2024-05-20 04:15:00         189.2366          189.1171         188.9977\n",
      "2024-05-20 04:20:00         189.2547          189.1236         188.9926\n",
      "Number of data points for autoencoders: 192\n",
      "\n",
      "--- 1-Hour Period Autoencoder Analysis ---\n",
      "Training 1-Hour Autoencoder (conceptual)...\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "1-Hour AE: Found 4 anomalies (threshold: 0.1435)\n",
      "--- Detailed 1-Hour Anomalies ---\n",
      "  Anomaly 1:\n",
      "    Timestamp: 2024-05-20 15:10:00\n",
      "    Reconstruction Error: 0.1515\n",
      "    Feature Values:\n",
      "Real Lower Band     190.2584\n",
      "Real Middle Band    190.5018\n",
      "Real Upper Band     190.7451\n",
      "--------------------\n",
      "  Anomaly 2:\n",
      "    Timestamp: 2024-05-20 15:15:00\n",
      "    Reconstruction Error: 0.1496\n",
      "    Feature Values:\n",
      "Real Lower Band     190.2551\n",
      "Real Middle Band    190.4928\n",
      "Real Upper Band     190.7305\n",
      "--------------------\n",
      "  Anomaly 3:\n",
      "    Timestamp: 2024-05-20 15:20:00\n",
      "    Reconstruction Error: 0.1472\n",
      "    Feature Values:\n",
      "Real Lower Band     190.2658\n",
      "Real Middle Band    190.4774\n",
      "Real Upper Band     190.6889\n",
      "--------------------\n",
      "  Anomaly 4:\n",
      "    Timestamp: 2024-05-20 15:25:00\n",
      "    Reconstruction Error: 0.1455\n",
      "    Feature Values:\n",
      "Real Lower Band     190.2767\n",
      "Real Middle Band    190.4649\n",
      "Real Upper Band     190.6530\n",
      "--------------------\n",
      "\n",
      "--- Multi-Interval Sequence Autoencoder Analysis (20 min sequences) ---\n",
      "Base interval: 5min, Sequence length: 4 intervals.\n",
      "Training Multi-Interval (20 min) Autoencoder...\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Multi-Interval (20 min) AE: Found 1 sequence anomalies (threshold: 0.0383)\n",
      "--- Detailed Multi-Interval (20 min) Sequence Anomalies ---\n",
      "  Anomaly Sequence 1:\n",
      "    Start Timestamp: 2024-05-20 15:00:00\n",
      "    Reconstruction Error (for sequence): 0.0383\n",
      "    Feature Values for each step in sequence:\n",
      "Real Lower Band     190.2745\n",
      "Real Middle Band    190.5191\n",
      "Real Upper Band     190.7638\n",
      "---\n",
      "Real Lower Band     190.2614\n",
      "Real Middle Band    190.5095\n",
      "Real Upper Band     190.7575\n",
      "---\n",
      "Real Lower Band     190.2584\n",
      "Real Middle Band    190.5018\n",
      "Real Upper Band     190.7451\n",
      "---\n",
      "Real Lower Band     190.2551\n",
      "Real Middle Band    190.4928\n",
      "Real Upper Band     190.7305\n",
      "--------------------\n",
      "\n",
      "--- 4-Hour Period Autoencoder Analysis ---\n",
      "Training 4-Hour Autoencoder (conceptual)...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import date, datetime, timedelta # Modified: Added datetime, timedelta\n",
    "import numpy as np # New import\n",
    "from sklearn.preprocessing import MinMaxScaler # New import\n",
    "from tensorflow.keras.models import Model # New import\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM # New import\n",
    "from tensorflow.keras.callbacks import EarlyStopping # New import\n",
    "\n",
    "load_dotenv()\n",
    "ALPHA_VANTAGE_API_KEY = os.getenv('ALPHA_VANTAGE_API_KEY')\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual Alpha Vantage API key\n",
    "API_KEY = ALPHA_VANTAGE_API_KEY\n",
    "SYMBOL = 'AAPL' # Apple Inc.\n",
    "\n",
    "# API Parameters\n",
    "# Modified to target a specific month for historical intraday data\n",
    "# For May 19th/20th, let's target May 2024.\n",
    "# Note: May 19, 2024 was a Sunday, May 20, 2024 was a Monday.\n",
    "# Adjust \"month\" if you need a different year/month.\n",
    "params = {\n",
    "    \"function\": \"BBANDS\",\n",
    "    \"symbol\": SYMBOL,\n",
    "    \"interval\": \"5min\",        # Set to \"5min\" for 5-min details, or \"60min\" for 1-hr details\n",
    "    \"month\": \"2024-05\",\n",
    "    \"time_period\": \"20\",\n",
    "    \"series_type\": \"close\",\n",
    "    \"apikey\": API_KEY,\n",
    "    \"datatype\": \"json\",\n",
    "    \"outputsize\": \"full\"\n",
    "}\n",
    "\n",
    "# Alpha Vantage API endpoint\n",
    "API_URL = \"https://www.alphavantage.co/query\"\n",
    "\n",
    "# --- Autoencoder Helper Functions ---\n",
    "def create_sequences(data, sequence_length):\n",
    "    \"\"\"\n",
    "    Creates sequences from the input data.\n",
    "    data: pandas DataFrame with features.\n",
    "    sequence_length: Number of time steps in each sequence.\n",
    "    \"\"\"\n",
    "    xs = []\n",
    "    for i in range(len(data) - sequence_length + 1):\n",
    "        xs.append(data.iloc[i:(i + sequence_length)].values)\n",
    "    return np.array(xs)\n",
    "\n",
    "def define_autoencoder(input_shape, encoding_dim_factor=0.5):\n",
    "    \"\"\"\n",
    "    Defines a simple autoencoder model.\n",
    "    input_shape: tuple, shape of the input data (sequence_length, num_features) or (num_features,)\n",
    "    encoding_dim_factor: determines the size of the bottleneck layer.\n",
    "    \"\"\"\n",
    "    num_features = input_shape[-1]\n",
    "    encoding_dim = int(encoding_dim_factor * num_features)\n",
    "    \n",
    "    if len(input_shape) == 2: # (sequence_length, num_features)\n",
    "        flat_input_dim = input_shape[0] * input_shape[1]\n",
    "    else: # (num_features,)\n",
    "        flat_input_dim = input_shape[0]\n",
    "    \n",
    "    input_layer = Input(shape=(flat_input_dim,))\n",
    "    encoded = Dense(int(flat_input_dim * 0.75), activation='relu')(input_layer)\n",
    "    encoded = Dense(int(flat_input_dim * 0.5), activation='relu')(encoded) # Bottleneck\n",
    "    decoded = Dense(int(flat_input_dim * 0.75), activation='relu')(encoded)\n",
    "    decoded = Dense(flat_input_dim, activation='sigmoid')(decoded) # Sigmoid if data scaled to 0-1\n",
    "\n",
    "    autoencoder = Model(input_layer, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder\n",
    "\n",
    "def get_reconstruction_error(data_scaled, model):\n",
    "    \"\"\"Calculates reconstruction error.\"\"\"\n",
    "    predictions = model.predict(data_scaled)\n",
    "    # For flattened sequences or single timesteps, axis=1 for mse per sample\n",
    "    mse = np.mean(np.power(data_scaled - predictions, 2), axis=1)\n",
    "    return mse\n",
    "# --- End Autoencoder Helper Functions ---\n",
    "\n",
    "try:\n",
    "    # Make the API request\n",
    "    response = requests.get(API_URL, params=params)\n",
    "    response.raise_for_status()  # Raise an exception for HTTP errors (4xx or 5xx)\n",
    "\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "\n",
    "    # Print the raw JSON data (or process it further)\n",
    "    # print(json.dumps(data, indent=4)) # Optionally keep this for debugging\n",
    "\n",
    "    # --- Optional: Further processing and visualization ---\n",
    "    # You can add more code here to process the data, for example, using pandas\n",
    "    # and matplotlib for plotting if the data is successfully retrieved.\n",
    "\n",
    "    # Example (if 'Technical Analysis: BBANDS' is in the response):\n",
    "    if \"Technical Analysis: BBANDS\" in data:\n",
    "        bbands_data = data[\"Technical Analysis: BBANDS\"]\n",
    "        # Convert to pandas DataFrame for easier manipulation and plotting\n",
    "        # import pandas as pd # Already imported at the top\n",
    "        # from datetime import date # Already imported at the top\n",
    "        df = pd.DataFrame.from_dict(bbands_data, orient='index')\n",
    "        df = df.astype(float) # Convert columns to numeric\n",
    "        df.index = pd.to_datetime(df.index) # Convert index to datetime\n",
    "        df = df.sort_index() # Sort by date\n",
    "\n",
    "        print(\"\\nFull Processed DataFrame (first 5 rows from fetched month):\")\n",
    "        print(df.head())\n",
    "\n",
    "        # Filter for the specific dates: May 19, 2024 and May 20, 2024\n",
    "        # Note: May 19, 2024 was a Sunday. May 20, 2024 was a Monday.\n",
    "        # You might only get data for May 20th.\n",
    "        target_start_date = datetime(2024, 5, 19)\n",
    "        target_end_date = datetime(2024, 5, 20, 23, 59, 59) # Include whole of May 20th\n",
    "\n",
    "        if not df.empty:\n",
    "            df_filtered = df[(df.index >= target_start_date) & (df.index <= target_end_date)]\n",
    "        else:\n",
    "            df_filtered = pd.DataFrame()\n",
    "\n",
    "        print(f\"\\nData for {target_start_date.strftime('%Y-%m-%d')} and {target_end_date.strftime('%Y-%m-%d')}:\")\n",
    "        if not df_filtered.empty:\n",
    "            print(df_filtered)\n",
    "        else:\n",
    "            print(\"No data found for the specified dates in the fetched data.\")\n",
    "            print(\"This could be due to non-trading days or API data limitations for the specified month/year.\")\n",
    "\n",
    "\n",
    "        if not df_filtered.empty:\n",
    "            print(f\"\\nFiltered DataFrame for Autoencoder analysis (first 5 rows):\")\n",
    "            print(df_filtered.head())\n",
    "            print(f\"Number of data points for autoencoders: {len(df_filtered)}\")\n",
    "            if len(df_filtered) < 10: # Arbitrary small number\n",
    "                print(\"WARNING: Very few data points for autoencoder training and testing.\")\n",
    "                print(\"Results will likely not be meaningful. Autoencoders need more data to learn patterns.\")\n",
    "\n",
    "\n",
    "            # --- Start Autoencoder Logic ---\n",
    "            features = ['Real Lower Band', 'Real Middle Band', 'Real Upper Band']\n",
    "            data_for_ae = df_filtered[features].copy()\n",
    "\n",
    "            # Scale data\n",
    "            scaler = MinMaxScaler()\n",
    "            data_scaled = scaler.fit_transform(data_for_ae)\n",
    "            \n",
    "            # --- 1-Hour Period Autoencoder ---\n",
    "            print(\"\\n--- 1-Hour Period Autoencoder Analysis ---\")\n",
    "            input_shape_1hr = (data_scaled.shape[1],) # (num_features,)\n",
    "            \n",
    "            train_size_1hr = int(len(data_scaled) * 0.7)\n",
    "            train_data_1hr = data_scaled[:train_size_1hr]\n",
    "            test_data_1hr = data_scaled[train_size_1hr:]\n",
    "            \n",
    "            if len(train_data_1hr) > 2 and len(test_data_1hr) > 0: # Reduced minimum for very small datasets\n",
    "                autoencoder_1hr = define_autoencoder(input_shape_1hr)\n",
    "                print(\"Training 1-Hour Autoencoder (conceptual)...\")\n",
    "                autoencoder_1hr.fit(train_data_1hr, train_data_1hr,\n",
    "                                    epochs=20, batch_size=16, shuffle=True, verbose=0,\n",
    "                                    validation_data=(test_data_1hr, test_data_1hr),\n",
    "                                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, mode='min')])\n",
    "\n",
    "                reconstruction_error_1hr = get_reconstruction_error(test_data_1hr, autoencoder_1hr)\n",
    "                threshold_1hr = np.mean(reconstruction_error_1hr) + 2 * np.std(reconstruction_error_1hr)\n",
    "                anomalies_1hr_indices_in_test = np.where(reconstruction_error_1hr > threshold_1hr)[0] # Renamed for clarity\n",
    "                \n",
    "                print(f\"1-Hour AE: Found {len(anomalies_1hr_indices_in_test)} anomalies (threshold: {threshold_1hr:.4f})\")\n",
    "                \n",
    "                if len(anomalies_1hr_indices_in_test) > 0:\n",
    "                    print(\"--- Detailed 1-Hour Anomalies ---\")\n",
    "                    # original_indices_1hr = df_filtered.index[train_size_1hr:][anomalies_1hr_indices_in_test] # Original way to get timestamps\n",
    "                    for i, anom_idx_in_test in enumerate(anomalies_1hr_indices_in_test):\n",
    "                        # Get the actual index in the original df_filtered\n",
    "                        original_df_idx = train_size_1hr + anom_idx_in_test\n",
    "                        timestamp = df_filtered.index[original_df_idx]\n",
    "                        anomaly_error = reconstruction_error_1hr[anom_idx_in_test]\n",
    "                        feature_values = df_filtered.iloc[original_df_idx][features]\n",
    "                        \n",
    "                        print(f\"  Anomaly {i+1}:\")\n",
    "                        print(f\"    Timestamp: {timestamp}\")\n",
    "                        print(f\"    Reconstruction Error: {anomaly_error:.4f}\")\n",
    "                        print(f\"    Feature Values:\\n{feature_values.to_string()}\")\n",
    "                        print(\"-\" * 20)\n",
    "            else:\n",
    "                print(\"Not enough data for 1-Hour Autoencoder training/testing example after splitting.\")\n",
    "                print(f\"  Available data points: {len(data_scaled)}, Train size: {len(train_data_1hr)}, Test size: {len(test_data_1hr)}\")\n",
    "\n",
    "            # --- Multi-Interval Sequence Autoencoder (Previously \"4-Hour\") ---\n",
    "            # This section creates sequences from the base interval data.\n",
    "            # The sequence_length determines how many base intervals form one sequence.\n",
    "            base_interval_str = params.get(\"interval\", \"unknown_interval\")\n",
    "            sequence_length_multi = 4 # Number of base intervals per sequence\n",
    "            \n",
    "            # Calculate actual duration of the sequence\n",
    "            interval_value = int(base_interval_str.replace('min','')) if 'min' in base_interval_str else 0\n",
    "            if interval_value > 0:\n",
    "                sequence_duration_minutes = sequence_length_multi * interval_value\n",
    "                if sequence_duration_minutes >= 60:\n",
    "                    sequence_duration_str = f\"{sequence_duration_minutes // 60} hour(s)\"\n",
    "                    if sequence_duration_minutes % 60 > 0:\n",
    "                        sequence_duration_str += f\" {sequence_duration_minutes % 60} min\"\n",
    "                else:\n",
    "                    sequence_duration_str = f\"{sequence_duration_minutes} min\"\n",
    "            else:\n",
    "                sequence_duration_str = f\"{sequence_length_multi} base intervals (unknown duration)\"\n",
    "\n",
    "            print(f\"\\n--- Multi-Interval Sequence Autoencoder Analysis ({sequence_duration_str} sequences) ---\")\n",
    "            print(f\"Base interval: {base_interval_str}, Sequence length: {sequence_length_multi} intervals.\")\n",
    "            \n",
    "            sequences_multi_original_shape = create_sequences(pd.DataFrame(data_scaled, columns=features), sequence_length_multi)\n",
    "            \n",
    "            if sequences_multi_original_shape.shape[0] > 0:\n",
    "                num_sequences = sequences_multi_original_shape.shape[0]\n",
    "                num_features_per_step = sequences_multi_original_shape.shape[2]\n",
    "                sequences_multi_flattened = sequences_multi_original_shape.reshape(num_sequences, sequence_length_multi * num_features_per_step)\n",
    "\n",
    "                input_shape_multi = (sequence_length_multi * num_features_per_step,)\n",
    "\n",
    "                train_size_multi = int(len(sequences_multi_flattened) * 0.7)\n",
    "                train_data_multi = sequences_multi_flattened[:train_size_multi]\n",
    "                test_data_multi = sequences_multi_flattened[train_size_multi:]\n",
    "\n",
    "                if len(train_data_multi) > 2 and len(test_data_multi) > 0: # Reduced minimum\n",
    "                    autoencoder_multi = define_autoencoder(input_shape_multi)\n",
    "                    print(f\"Training Multi-Interval ({sequence_duration_str}) Autoencoder...\")\n",
    "                    autoencoder_multi.fit(train_data_multi, train_data_multi,\n",
    "                                        epochs=20, batch_size=16, shuffle=True, verbose=0,\n",
    "                                        validation_data=(test_data_multi, test_data_multi),\n",
    "                                        callbacks=[EarlyStopping(monitor='val_loss', patience=3, mode='min')])\n",
    "                    \n",
    "                    reconstruction_error_multi = get_reconstruction_error(test_data_multi, autoencoder_multi)\n",
    "                    threshold_multi = np.mean(reconstruction_error_multi) + 2 * np.std(reconstruction_error_multi)\n",
    "                    anomalies_multi_indices_in_test = np.where(reconstruction_error_multi > threshold_multi)[0]\n",
    "\n",
    "                    print(f\"Multi-Interval ({sequence_duration_str}) AE: Found {len(anomalies_multi_indices_in_test)} sequence anomalies (threshold: {threshold_multi:.4f})\")\n",
    "                    \n",
    "                    if len(anomalies_multi_indices_in_test) > 0:\n",
    "                        print(f\"--- Detailed Multi-Interval ({sequence_duration_str}) Sequence Anomalies ---\")\n",
    "                        for i, anom_idx_in_test in enumerate(anomalies_multi_indices_in_test):\n",
    "                            # original_df_idx is the start of the anomalous sequence in df_filtered\n",
    "                            original_df_idx_start_of_sequence = train_size_multi + anom_idx_in_test\n",
    "                            \n",
    "                            # Ensure the sequence start index is valid for df_filtered\n",
    "                            if original_df_idx_start_of_sequence < (len(df_filtered) - sequence_length_multi + 1):\n",
    "                                timestamp_start = df_filtered.index[original_df_idx_start_of_sequence]\n",
    "                                anomaly_error = reconstruction_error_multi[anom_idx_in_test]\n",
    "                                \n",
    "                                # Get feature values for the entire anomalous sequence\n",
    "                                sequence_feature_values_list = []\n",
    "                                for step in range(sequence_length_multi):\n",
    "                                    step_idx = original_df_idx_start_of_sequence + step\n",
    "                                    if step_idx < len(df_filtered):\n",
    "                                        sequence_feature_values_list.append(df_filtered.iloc[step_idx][features].to_string())\n",
    "                                    else:\n",
    "                                        sequence_feature_values_list.append(\"Data point out of bounds\")\n",
    "                                sequence_feature_values_str = \"\\n---\\n\".join(sequence_feature_values_list)\n",
    "\n",
    "                                print(f\"  Anomaly Sequence {i+1}:\")\n",
    "                                print(f\"    Start Timestamp: {timestamp_start}\")\n",
    "                                print(f\"    Reconstruction Error (for sequence): {anomaly_error:.4f}\")\n",
    "                                print(f\"    Feature Values for each step in sequence:\\n{sequence_feature_values_str}\")\n",
    "                                print(\"-\" * 20)\n",
    "                            else:\n",
    "                                print(f\"  Anomaly Sequence {i+1} (index {original_df_idx_start_of_sequence}) out of bounds for detailed view.\")\n",
    "                else:\n",
    "                    print(f\"Not enough data for Multi-Interval ({sequence_duration_str}) Autoencoder training/testing example after splitting.\")\n",
    "                    print(f\"  Available sequences: {len(sequences_multi_flattened)}, Train sequences: {len(train_data_multi)}, Test sequences: {len(test_data_multi)}\")\n",
    "            else:\n",
    "                print(f\"Not enough data to create {sequence_duration_str} sequences from the filtered data.\")\n",
    "            # --- 5-Minute Period Autoencoder (More Sensitive) ---\n",
    "            print(\"\\n--- 4-Hour Period Autoencoder Analysis ---\")\n",
    "            sequence_length_4hr = 4 \n",
    "            \n",
    "            sequences_4hr_original_shape = create_sequences(pd.DataFrame(data_scaled, columns=features), sequence_length_4hr)\n",
    "            \n",
    "            if sequences_4hr_original_shape.shape[0] > 0:\n",
    "                num_sequences = sequences_4hr_original_shape.shape[0]\n",
    "                num_features_per_step = sequences_4hr_original_shape.shape[2]\n",
    "                sequences_4hr_flattened = sequences_4hr_original_shape.reshape(num_sequences, sequence_length_4hr * num_features_per_step)\n",
    "\n",
    "                input_shape_4hr = (sequence_length_4hr * num_features_per_step,)\n",
    "\n",
    "                train_size_4hr = int(len(sequences_4hr_flattened) * 0.7)\n",
    "                train_data_4hr = sequences_4hr_flattened[:train_size_4hr]\n",
    "                test_data_4hr = sequences_4hr_flattened[train_size_4hr:]\n",
    "\n",
    "                if len(train_data_4hr) > 2 and len(test_data_4hr) > 0: # Reduced minimum\n",
    "                    autoencoder_4hr = define_autoencoder(input_shape_4hr)\n",
    "                    print(\"Training 4-Hour Autoencoder (conceptual)...\")\n",
    "                    autoencoder_4hr.fit(train_data_4hr, train_data_4hr,\n",
    "                                        epochs=20, batch_size=16, shuffle=True, verbose=0,\n",
    "                                        validation_data=(test_data_4hr, test_data_4hr),\n",
    "                                        callbacks=[EarlyStopping(monitor='val_loss', patience=3, mode='min')])\n",
    "                    \n",
    "                    reconstruction_error_4hr = get_reconstruction_error(test_data_4hr, autoencoder_4hr)\n",
    "                    threshold_4hr = np.mean(reconstruction_error_4hr) + 2 * np.std(reconstruction_error_4hr)\n",
    "                    anomalies_4hr_indices = np.where(reconstruction_error_4hr > threshold_4hr)[0]\n",
    "\n",
    "                    print(f\"4-Hour AE: Found {len(anomalies_4hr_indices)} sequence anomalies (threshold: {threshold_4hr:.4f})\")\n",
    "                    if anomalies_4hr_indices.size > 0:\n",
    "                        print(\"Anomaly start timestamps (4-hour sequences):\")\n",
    "                        for anom_idx in anomalies_4hr_indices:\n",
    "                            original_df_idx = train_size_4hr + anom_idx\n",
    "                            if original_df_idx < len(df_filtered) - sequence_length_4hr + 1:\n",
    "                                print(df_filtered.index[original_df_idx])\n",
    "                else:\n",
    "                    print(\"Not enough data for 4-Hour Autoencoder training/testing example after splitting.\")\n",
    "                    print(f\"  Available sequences: {len(sequences_4hr_flattened)}, Train sequences: {len(train_data_4hr)}, Test sequences: {len(test_data_4hr)}\")\n",
    "            else:\n",
    "                print(\"Not enough data to create 4-hour sequences from the filtered data.\")\n",
    "            # --- End Autoencoder Logic ---\n",
    "\n",
    "            # --- 5-Minute Period Autoencoder (More Sensitive) ---\n",
    "            print(\"\\n--- 5-Minute Period Autoencoder Analysis ---\")\n",
    "            sequence_length_5min = 4 \n",
    "            \n",
    "            sequences_5min_original_shape = create_sequences(pd.DataFrame(data_scaled, columns=features), sequence_length_5min)\n",
    "            \n",
    "            if sequences_5min_original_shape.shape[0] > 0:\n",
    "                num_sequences = sequences_5min_original_shape.shape[0]\n",
    "                num_features_per_step = sequences_5min_original_shape.shape[2]\n",
    "                sequences_5min_flattened = sequences_5min_original_shape.reshape(num_sequences, sequence_length_5min * num_features_per_step)\n",
    "\n",
    "                input_shape_5min = (sequence_length_5min * num_features_per_step,)\n",
    "\n",
    "                train_size_5min = int(len(sequences_5min_flattened) * 0.7)\n",
    "                train_data_5min = sequences_5min_flattened[:train_size_5min]\n",
    "                test_data_5min = sequences_5min_flattened[train_size_5min:]\n",
    "\n",
    "                if len(train_data_5min) > 2 and len(test_data_5min) > 0: # Reduced minimum\n",
    "                    autoencoder_5min = define_autoencoder(input_shape_5min)\n",
    "                    print(\"Training 5-Minute Autoencoder...\")\n",
    "                    autoencoder_5min.fit(train_data_5min, train_data_5min,\n",
    "                                        epochs=20, batch_size=16, shuffle=True, verbose=0,\n",
    "                                        validation_data=(test_data_5min, test_data_5min),\n",
    "                                        callbacks=[EarlyStopping(monitor='val_loss', patience=3, mode='min')])\n",
    "                    \n",
    "                    reconstruction_error_5min = get_reconstruction_error(test_data_5min, autoencoder_5min)\n",
    "                    threshold_5min = np.mean(reconstruction_error_5min) + 2 * np.std(reconstruction_error_5min)\n",
    "                    anomalies_5min_indices = np.where(reconstruction_error_5min > threshold_5min)[0]\n",
    "\n",
    "                    print(f\"5-Minute AE: Found {len(anomalies_5min_indices)} sequence anomalies (threshold: {threshold_5min:.4f})\")\n",
    "                    if anomalies_5min_indices.size > 0:\n",
    "                        print(\"Anomaly start timestamps (5-minute sequences):\")\n",
    "                        for anom_idx in anomalies_5min_indices:\n",
    "                            original_df_idx = train_size_5min + anom_idx\n",
    "                            if original_df_idx < len(df_filtered) - sequence_length_5min + 1:\n",
    "                                print(df_filtered.index[original_df_idx])\n",
    "                else:\n",
    "                    print(\"Not enough data for 5-Minute Autoencoder training/testing example after splitting.\")\n",
    "                    print(f\"  Available sequences: {len(sequences_5min_flattened)}, Train sequences: {len(train_data_5min)}, Test sequences: {len(test_data_5min)}\")\n",
    "            else:\n",
    "                print(\"Not enough data to create 5-minute sequences from the filtered data.\")\n",
    "            # --- End Autoencoder Logic ---\n",
    "\n",
    "            # After your autoencoder analysis, add this plotting code:\n",
    "            import matplotlib.pyplot as plt\n",
    "            import matplotlib.dates as mdates\n",
    "            from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "            # Filter for just trading hours (9:30 AM - 4:00 PM ET)\n",
    "            # For May 20, 2024 (Monday)\n",
    "            trading_start = datetime(2024, 5, 20, 9, 30)  # 9:30 AM ET\n",
    "            trading_end = datetime(2024, 5, 20, 16, 0)    # 4:00 PM ET\n",
    "\n",
    "            # Filter data for trading hours\n",
    "            trading_hours_data = df_filtered[(df_filtered.index >= trading_start) & \n",
    "                                             (df_filtered.index <= trading_end)]\n",
    "\n",
    "            if not trading_hours_data.empty:\n",
    "                # Create Figure 1 - Bollinger Bands with Anomalies\n",
    "                plt.figure(figsize=(14, 8))\n",
    "                plt.title('AAPL Bollinger Bands with Anomaly Detection (May 20, 2024 Trading Hours)', fontsize=14)\n",
    "                \n",
    "                # Plot Bollinger Bands\n",
    "                plt.plot(trading_hours_data.index, trading_hours_data['Real Middle Band'], 'b-', label='Middle Band (SMA)')\n",
    "                plt.plot(trading_hours_data.index, trading_hours_data['Real Upper Band'], 'g-', label='Upper Band')\n",
    "                plt.plot(trading_hours_data.index, trading_hours_data['Real Lower Band'], 'r-', label='Lower Band')\n",
    "                \n",
    "                # Plot anomalies if they exist\n",
    "                # 1-Hour anomalies\n",
    "                if 'anomalies_1hr_indices_in_test' in locals() and len(anomalies_1hr_indices_in_test) > 0:\n",
    "                    anomaly_timestamps = []\n",
    "                    for anom_idx in anomalies_1hr_indices_in_test:\n",
    "                        original_df_idx = train_size_1hr + anom_idx\n",
    "                        if original_df_idx < len(df_filtered):\n",
    "                            timestamp = df_filtered.index[original_df_idx]\n",
    "                            if trading_start <= timestamp <= trading_end:\n",
    "                                anomaly_timestamps.append(timestamp)\n",
    "                        \n",
    "                        if anomaly_timestamps:\n",
    "                            plt.scatter(anomaly_timestamps, \n",
    "                                       trading_hours_data.loc[anomaly_timestamps]['Real Middle Band'],\n",
    "                                       color='purple', marker='o', s=100, label='1-Hr Anomaly')\n",
    "                    \n",
    "                    # 5-Minute anomalies\n",
    "                    if 'anomalies_5min_indices' in locals() and anomalies_5min_indices.size > 0:\n",
    "                        anomaly_timestamps_5min = []\n",
    "                        for anom_idx in anomalies_5min_indices:\n",
    "                            original_df_idx = train_size_5min + anom_idx\n",
    "                            if original_df_idx < len(df_filtered) - sequence_length_5min + 1:\n",
    "                                timestamp = df_filtered.index[original_df_idx]\n",
    "                                if trading_start <= timestamp <= trading_end:\n",
    "                                    anomaly_timestamps_5min.append(timestamp)\n",
    "                        \n",
    "                        if anomaly_timestamps_5min:\n",
    "                            plt.scatter(anomaly_timestamps_5min,\n",
    "                                       trading_hours_data.loc[anomaly_timestamps_5min]['Real Middle Band'],\n",
    "                                       color='red', marker='x', s=80, label='5-Min Anomaly')\n",
    "                    \n",
    "                    # Multi-interval anomalies\n",
    "                    if 'anomalies_multi_indices_in_test' in locals() and len(anomalies_multi_indices_in_test) > 0:\n",
    "                        anomaly_timestamps_multi = []\n",
    "                        for anom_idx in anomalies_multi_indices_in_test:\n",
    "                            original_df_idx = train_size_multi + anom_idx\n",
    "                            if original_df_idx < len(df_filtered) - sequence_length_multi + 1:\n",
    "                                timestamp = df_filtered.index[original_df_idx]\n",
    "                                if trading_start <= timestamp <= trading_end:\n",
    "                                    anomaly_timestamps_multi.append(timestamp)\n",
    "                        \n",
    "                        if anomaly_timestamps_multi:\n",
    "                            plt.scatter(anomaly_timestamps_multi,\n",
    "                                       trading_hours_data.loc[anomaly_timestamps_multi]['Real Middle Band'],\n",
    "                                       color='orange', marker='s', s=80, label=f'Multi-Interval ({sequence_duration_str}) Anomaly')\n",
    "                    \n",
    "                    # Format x-axis to show all trading hour intervals\n",
    "                    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "                    plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=1))\n",
    "                    plt.gca().xaxis.set_minor_locator(mdates.MinuteLocator(byminute=[0, 15, 30, 45]))\n",
    "                    \n",
    "                    plt.xlabel('Time (May 20, 2024)', fontsize=12)\n",
    "                    plt.ylabel('Price', fontsize=12)\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                    plt.legend(loc='best')\n",
    "                    \n",
    "                    # Rotate date labels for better readability\n",
    "                    plt.gcf().autofmt_xdate()\n",
    "                    \n",
    "                    # Add a note about trading hours\n",
    "                    plt.figtext(0.5, 0.01, 'Note: Normal Trading Hours (9:30 AM - 4:00 PM ET)', \n",
    "                                ha='center', fontsize=10, style='italic')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig('aapl_bollinger_bands_with_anomalies.png', dpi=300)\n",
    "                    plt.show()\n",
    "            else:\n",
    "                print(\"No data available for trading hours on May 20, 2024.\")\n",
    "            # Example plotting (requires matplotlib)\n",
    "            import matplotlib.pyplot as plt # Ensure matplotlib is imported\n",
    "            plt.figure(figsize=(15,7)) # Adjusted figure size\n",
    "            plt.plot(df_filtered.index, df_filtered['Real Middle Band'], label='Middle Band')\n",
    "            plt.plot(df_filtered.index, df_filtered['Real Upper Band'], label='Upper Band', color='red')\n",
    "            plt.plot(df_filtered.index, df_filtered['Real Lower Band'], label='Lower Band', color='green')\n",
    "            plt.fill_between(df_filtered.index, df_filtered['Real Lower Band'], df_filtered['Real Upper Band'], color='gray', alpha=0.3)\n",
    "            \n",
    "            # --- Plotting Anomalies ---\n",
    "            if 'original_indices_1hr' in locals() and not original_indices_1hr.empty:\n",
    "                 plt.scatter(original_indices_1hr, \n",
    "                            df_filtered.loc[original_indices_1hr]['Real Middle Band'], # Plot on middle band\n",
    "                            color='purple', marker='o', s=100, label='1-Hr Anomaly')\n",
    "\n",
    "            if 'anomalies_5min_indices' in locals() and anomalies_5min_indices.size > 0 and 'train_size_5min' in locals() and 'sequence_length_5min' in locals():\n",
    "                anom_starts_5min_plot = []\n",
    "                # For plotting, we need the indices from the 'multi-interval' section\n",
    "                # Assuming anomalies_multi_indices_in_test and train_size_multi are now the correct variables\n",
    "                if 'anomalies_multi_indices_in_test' in locals() and len(anomalies_multi_indices_in_test) > 0:\n",
    "                    for anom_idx in anomalies_multi_indices_in_test:\n",
    "                        original_df_idx = train_size_multi + anom_idx # This is index in sequences_multi_flattened\n",
    "                        # The corresponding index in df_filtered is the start of the sequence\n",
    "                        if original_df_idx < (len(df_filtered) - sequence_length_multi + 1):\n",
    "                             anom_starts_5min_plot.append(df_filtered.index[original_df_idx])\n",
    "                    if anom_starts_5min_plot:\n",
    "                        plt.scatter(anom_starts_5min_plot,\n",
    "                                    df_filtered.loc[anom_starts_5min_plot]['Real Middle Band'], # Plot on middle band\n",
    "                                    color='orange', marker='X', s=150, label=f'{sequence_duration_str} Anomaly Start')\n",
    "            \n",
    "            if 'original_indices_5min' in locals() and not original_indices_5min.empty:\n",
    "                 plt.scatter(original_indices_5min, \n",
    "                            df_filtered.loc[original_indices_5min]['Real Middle Band'], # Plot on middle band\n",
    "                            color='cyan', marker='P', s=120, label='5-Min Anomaly (Sensitive)')\n",
    "            # --- End Plotting Anomalies ---\n",
    "\n",
    "            plt.title(f'Bollinger Bands for {SYMBOL} (5min interval)') # Updated title\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Price')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        else:\n",
    "            # print(f\"\\nNo data found for the period {start_date} to {end_date}.\") # Original message\n",
    "            print(f\"\\nNo data found for the period for analysis.\") # Updated message\n",
    "\n",
    "    else:\n",
    "        print(\"\\nCould not find 'Technical Analysis: BBANDS' in the API response.\")\n",
    "        # --- Additions for more API error info ---\n",
    "        if \"Error Message\" in data:\n",
    "            print(f\"API Error: {data['Error Message']}\")\n",
    "        elif \"Information\" in data: \n",
    "            print(f\"API Info: {data['Information']}\") # Often indicates API call limit reached or other issues\n",
    "        # --- End Additions ---\n",
    "\n",
    "except requests.exceptions.HTTPError as http_err:\n",
    "    print(f\"HTTP error occurred: {http_err}\")\n",
    "except requests.exceptions.ConnectionError as conn_err:\n",
    "    print(f\"Connection error occurred: {conn_err}\")\n",
    "except requests.exceptions.Timeout as timeout_err:\n",
    "    print(f\"Timeout error occurred: {timeout_err}\")\n",
    "except requests.exceptions.RequestException as req_err:\n",
    "    print(f\"An error occurred during the request: {req_err}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Failed to decode JSON response. Raw response:\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin-ai1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
