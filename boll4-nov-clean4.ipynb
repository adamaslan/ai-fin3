{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7266287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--ticker TICKER]\n",
      "                             [--history-days HISTORY_DAYS]\n",
      "                             [--gcp-bucket GCP_BUCKET]\n",
      "                             [--mistral-key MISTRAL_KEY]\n",
      "                             [--mistral-model MISTRAL_MODEL]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/Users/adamaslan/Library/Jupyter/runtime/kernel-v34b8a01b7ee8201b01f31366bb4442f2de210d850.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Enhanced AI-Enhanced Options Spread Analysis with GCP Storage\n",
    "- Uses pathlib, robust logging, retries & exponential backoff\n",
    "- Prefers google.cloud.storage client but falls back to gcloud CLI (subprocess) if needed\n",
    "- Safer handling of secrets; supports Application Default Credentials (recommended)\n",
    "- Improved Mistral SDK use with retry/backoff\n",
    "- More robust technical indicator calculations (safer divisions, NaN handling)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from datetime import date, datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# External cloud & AI SDKs (ensure installed + configured)\n",
    "from google.cloud import storage\n",
    "from mistralai import Mistral\n",
    "\n",
    "# ---------- Configuration ----------\n",
    "TICKER = \"SPY\"\n",
    "DAYS_OF_HISTORY = 90  # use a longer window for indicators calculation; change as desired\n",
    "GCP_BUCKET = \"ttb-bucket1\"\n",
    "LOCAL_SAVE_DIR = Path.cwd() / \"spreads-yo\"\n",
    "LOCAL_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Mistral config\n",
    "MISTRAL_MODEL = \"mistral-small-latest\"  # keep as before\n",
    "# load .env if exists\n",
    "load_dotenv()  # will read .env in cwd or environment\n",
    "\n",
    "# Read API keys from environment (prefer ADC for GCP, avoid injecting service account keys)\n",
    "MISTRAL_API_KEY = None\n",
    "if \"MISTRAL_API_KEY\" in (env := dict()):\n",
    "    pass  # keep the pattern - we will read from os.environ below\n",
    "\n",
    "import os\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\", \"\")\n",
    "# Note: For GCP, prefer Application Default Credentials (ADC), or configure `gcloud auth application-default login`\n",
    "# If you must use a service account key, use environment variable GOOGLE_APPLICATION_CREDENTIALS pointing to the key file\n",
    "# but avoid putting long keys into environment variables.\n",
    "\n",
    "# ---------- Logging ----------\n",
    "LOG_LEVEL = logging.INFO\n",
    "logging.basicConfig(\n",
    "    level=LOG_LEVEL,\n",
    "    format=\"%(asctime)s %(levelname)s %(name)s: %(message)s\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "logger = logging.getLogger(\"spread_analysis\")\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def safe_div(numerator: float, denominator: float, default: Optional[float] = None) -> Optional[float]:\n",
    "    try:\n",
    "        if denominator is None or math.isclose(denominator, 0.0):\n",
    "            return default\n",
    "        return numerator / denominator\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def retry_with_backoff(\n",
    "    func,\n",
    "    max_retries: int = 4,\n",
    "    initial_delay: float = 1.0,\n",
    "    multiplier: float = 2.0,\n",
    "    retry_on_exceptions: tuple = (Exception,),\n",
    "    on_retry: Optional[callable] = None,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generic retry wrapper. `func` is called with kwargs.\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    while True:\n",
    "        try:\n",
    "            return func(**kwargs)\n",
    "        except retry_on_exceptions as e:\n",
    "            attempt += 1\n",
    "            if attempt > max_retries:\n",
    "                logger.exception(\"Max retries exceeded for function %s\", getattr(func, \"__name__\", str(func)))\n",
    "                raise\n",
    "            delay = initial_delay * (multiplier ** (attempt - 1))\n",
    "            logger.warning(\"Retryable error: %s. Retrying in %.1f seconds (attempt %d/%d).\", e, delay, attempt, max_retries)\n",
    "            if on_retry:\n",
    "                try:\n",
    "                    on_retry(attempt, e)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            time.sleep(delay)\n",
    "\n",
    "# ---------- Technical indicators ----------\n",
    "def calculate_technical_indicators(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Input: df must contain ['Open','High','Low','Close','Volume'] indexed by date\n",
    "    Returns: dictionary of the latest computed indicators (dropna handled internally)\n",
    "    \"\"\"\n",
    "    df = df.copy().sort_index()\n",
    "\n",
    "    # Ensure numeric and drop rows with missing price/volume\n",
    "    required_columns = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "    df = df.dropna(subset=required_columns)\n",
    "    for col in required_columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # 50 and 200 SMA\n",
    "    df[\"SMA_50\"] = df[\"Close\"].rolling(window=50, min_periods=10).mean()\n",
    "    df[\"SMA_200\"] = df[\"Close\"].rolling(window=200, min_periods=50).mean()\n",
    "\n",
    "    # RSI (14) using simple method\n",
    "    delta = df[\"Close\"].diff()\n",
    "    up = delta.clip(lower=0)\n",
    "    down = -delta.clip(upper=0)\n",
    "    roll_up = up.rolling(window=14, min_periods=7).mean()\n",
    "    roll_down = down.rolling(window=14, min_periods=7).mean()\n",
    "    rs = roll_up / roll_down.replace(0, np.nan)\n",
    "    df[\"RSI\"] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # MACD\n",
    "    exp1 = df[\"Close\"].ewm(span=12, adjust=False).mean()\n",
    "    exp2 = df[\"Close\"].ewm(span=26, adjust=False).mean()\n",
    "    df[\"MACD\"] = exp1 - exp2\n",
    "    df[\"Signal_Line\"] = df[\"MACD\"].ewm(span=9, adjust=False).mean()\n",
    "    df[\"MACD_Bullish\"] = df[\"MACD\"] > df[\"Signal_Line\"]\n",
    "\n",
    "    # Bollinger Bands %B\n",
    "    window = 20\n",
    "    ma = df[\"Close\"].rolling(window=window, min_periods=10).mean()\n",
    "    std = df[\"Close\"].rolling(window=window, min_periods=10).std()\n",
    "    df[\"Upper_Band\"] = ma + 2 * std\n",
    "    df[\"Lower_Band\"] = ma - 2 * std\n",
    "    df[\"BB_PercentB\"] = (df[\"Close\"] - df[\"Lower_Band\"]) / (df[\"Upper_Band\"] - df[\"Lower_Band\"]).replace(0, np.nan)\n",
    "\n",
    "    # Historical Volatility (30-day)\n",
    "    df[\"Log_Return\"] = np.log(df[\"Close\"] / df[\"Close\"].shift(1))\n",
    "    df[\"HV_30d\"] = df[\"Log_Return\"].rolling(window=30, min_periods=10).std() * np.sqrt(252)\n",
    "\n",
    "    # ATR (14)\n",
    "    high_low = df[\"High\"] - df[\"Low\"]\n",
    "    high_close = (df[\"High\"] - df[\"Close\"].shift()).abs()\n",
    "    low_close = (df[\"Low\"] - df[\"Close\"].shift()).abs()\n",
    "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    df[\"ATR\"] = tr.ewm(span=14, adjust=False).mean()\n",
    "\n",
    "    # Avg volume (50)\n",
    "    df[\"Avg_Volume_50\"] = df[\"Volume\"].rolling(window=50, min_periods=10).mean()\n",
    "\n",
    "    # ROC 10d\n",
    "    df[\"ROC_10d\"] = (df[\"Close\"].diff(periods=10) / df[\"Close\"].shift(10)) * 100\n",
    "\n",
    "    # Stochastic %K\n",
    "    low_14 = df[\"Low\"].rolling(window=14, min_periods=7).min()\n",
    "    high_14 = df[\"High\"].rolling(window=14, min_periods=7).max()\n",
    "    df[\"Stoch_K\"] = 100 * safe_div((df[\"Close\"] - low_14), (high_14 - low_14), default=np.nan)\n",
    "\n",
    "    # Money Flow Index (14)\n",
    "    typical_price = (df[\"High\"] + df[\"Low\"] + df[\"Close\"]) / 3\n",
    "    mf = typical_price * df[\"Volume\"]\n",
    "    positive_flow = mf.where(typical_price > typical_price.shift(1), 0).rolling(window=14).sum()\n",
    "    negative_flow = mf.where(typical_price < typical_price.shift(1), 0).rolling(window=14).sum()\n",
    "    money_ratio = safe_div(positive_flow, negative_flow, default=np.nan)\n",
    "    df[\"MFI\"] = 100 - (100 / (1 + money_ratio))\n",
    "\n",
    "    # Accumulation/Distribution Line (ADL)\n",
    "    denom = (df[\"High\"] - df[\"Low\"]).replace(0, np.nan)\n",
    "    money_flow_multiplier = safe_div(((df[\"Close\"] - df[\"Low\"]) - (df[\"High\"] - df[\"Close\"])), denom, default=0.0)\n",
    "    df[\"Money_Flow_Volume\"] = money_flow_multiplier * df[\"Volume\"]\n",
    "    df[\"ADL\"] = df[\"Money_Flow_Volume\"].cumsum()\n",
    "\n",
    "    df = df.dropna(how=\"all\")  # drop rows entirely NaN\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Dataframe empty after indicator calculations\")\n",
    "\n",
    "    latest = df.iloc[-1].to_dict()\n",
    "\n",
    "    # Build indicator dict with safe defaults\n",
    "    indicators = {\n",
    "        \"Current_Price\": float(latest.get(\"Close\", np.nan)),\n",
    "        \"SMA_50\": float(latest.get(\"SMA_50\", np.nan)),\n",
    "        \"SMA_200\": float(latest.get(\"SMA_200\", np.nan)),\n",
    "        \"RSI\": float(latest.get(\"RSI\", np.nan)),\n",
    "        \"MACD_Value\": float(latest.get(\"MACD\", np.nan)),\n",
    "        \"MACD_Signal\": float(latest.get(\"Signal_Line\", np.nan)),\n",
    "        \"MACD_Bullish\": bool(latest.get(\"MACD_Bullish\", False)),\n",
    "        \"BB_PercentB\": float(latest.get(\"BB_PercentB\", np.nan)),\n",
    "        \"HV_30d\": float(latest.get(\"HV_30d\", np.nan)),\n",
    "        \"ATR\": float(latest.get(\"ATR\", np.nan)),\n",
    "        \"Avg_Volume_50\": float(latest.get(\"Avg_Volume_50\", np.nan)),\n",
    "        \"ROC_10d\": float(latest.get(\"ROC_10d\", np.nan)),\n",
    "        \"Stoch_K\": float(latest.get(\"Stoch_K\", np.nan)),\n",
    "        \"MFI\": float(latest.get(\"MFI\", np.nan)),\n",
    "        \"ADL\": float(latest.get(\"ADL\", np.nan)),\n",
    "    }\n",
    "    return indicators\n",
    "\n",
    "# ---------- Mistral integration ----------\n",
    "def quick_mistral_test(api_key: str, model: str) -> bool:\n",
    "    if not api_key:\n",
    "        logger.warning(\"Mistral API key not configured. Skipping Mistral test.\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        logger.info(\"Testing Mistral connectivity...\")\n",
    "        with Mistral(api_key=api_key) as mistral:\n",
    "            res = mistral.chat.complete(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": \"Respond with a single word: Connected\"}],\n",
    "                temperature=0.1,\n",
    "                max_tokens=10,\n",
    "                stream=False,\n",
    "            )\n",
    "        # Validate response\n",
    "        if res and getattr(res, \"choices\", None):\n",
    "            text = getattr(res.choices[0].message, \"content\", \"\")\n",
    "            if \"connected\" in text.lower():\n",
    "                logger.info(\"Mistral connectivity OK (model=%s).\", model)\n",
    "                return True\n",
    "            logger.warning(\"Mistral returned unexpected text: %s\", text)\n",
    "            return True\n",
    "        logger.warning(\"Mistral returned no usable content.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Mistral test failed: %s\", e)\n",
    "        return False\n",
    "\n",
    "def generate_ai_rationale(\n",
    "    api_key: str,\n",
    "    model: str,\n",
    "    spread_data: Dict[str, Any],\n",
    "    indicators: Dict[str, Any],\n",
    "    max_retries: int = 3,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a paragraph explaining the trade using Mistral. Uses exponential backoff on failures.\n",
    "    Returns a string (or error text) — never raises.\n",
    "    \"\"\"\n",
    "    if not api_key:\n",
    "        return \"AI rationale skipped: Mistral API key not configured.\"\n",
    "\n",
    "    # Build prompt (careful with types)\n",
    "    prompt = f\"\"\"\n",
    "You are a quantitative financial analyst. Generate a single detailed paragraph analyzing a {spread_data['type']} for {TICKER}.\n",
    "\n",
    "Market context:\n",
    "- Current Price: ${indicators['Current_Price']:.2f}\n",
    "- SMA50: {indicators['SMA_50']:.2f}, SMA200: {indicators['SMA_200']:.2f}\n",
    "- RSI: {indicators['RSI']:.2f}\n",
    "- MACD: {indicators['MACD_Value']:.2f} (Signal {indicators['MACD_Signal']:.2f})\n",
    "- Stochastic %K: {indicators['Stoch_K']:.2f}\n",
    "- HV_30d: {indicators['HV_30d']:.2f}\n",
    "- BB%: {indicators['BB_PercentB']:.2f}å\n",
    "- MFI: {indicators['MFI']:.2f}\n",
    "Trade specifics:\n",
    "- Sell {spread_data['sell_strike']}, Buy {spread_data['buy_strike']}, Exp: {spread_data['expiration']}\n",
    "- Est credit: ${spread_data['max_profit']}, Max loss: ${spread_data['max_loss']}\n",
    "Provide a sophisticated paragraph linking indicators to the trade thesis. Include risk/reward and short disclaimer.\n",
    "\"\"\"\n",
    "\n",
    "    def call_mistral_once(api_key_local: str, model_local: str, prompt_text: str):\n",
    "        with Mistral(api_key=api_key_local) as mistral:\n",
    "            res = mistral.chat.complete(\n",
    "                model=model_local,\n",
    "                messages=[{\"role\": \"system\", \"content\": \"You are a quantitative financial analyst.\"},\n",
    "                          {\"role\": \"user\", \"content\": prompt_text}],\n",
    "                temperature=0.5,\n",
    "                max_tokens=600,\n",
    "                top_p=1.0,\n",
    "                frequency_penalty=0.1,\n",
    "                presence_penalty=0.1,\n",
    "                stream=False,\n",
    "                n=1,\n",
    "                response_format={\"type\": \"text\"},\n",
    "            )\n",
    "        # Try to extract text safely\n",
    "        try:\n",
    "            text = res.choices[0].message.content.strip()\n",
    "            return text\n",
    "        except Exception:\n",
    "            # Fallback: attempt attribute-style extraction\n",
    "            try:\n",
    "                return str(res)\n",
    "            except Exception:\n",
    "                raise ValueError(\"Empty response structure from Mistral\")\n",
    "\n",
    "    try:\n",
    "        return retry_with_backoff(\n",
    "            func=call_mistral_once,\n",
    "            max_retries=max_retries,\n",
    "            initial_delay=2.0,\n",
    "            multiplier=2.0,\n",
    "            retry_on_exceptions=(Exception,),\n",
    "            api_key_local=api_key,\n",
    "            model_local=model,\n",
    "            prompt_text=prompt,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Failed to generate AI rationale: %s\", e)\n",
    "        return f\"ERROR: Failed to generate AI rationale. Details: {e}\"\n",
    "\n",
    "# ---------- GCP upload helpers ----------\n",
    "def upload_with_python_client(bucket_name: str, files: List[Path], destination_prefix: str) -> bool:\n",
    "    \"\"\"\n",
    "    Uploads list of local files to bucket using google.cloud.storage.\n",
    "    Returns True on success, False on any error.\n",
    "    \"\"\"\n",
    "    logger.info(\"Uploading using google.cloud.storage client to bucket %s\", bucket_name)\n",
    "    try:\n",
    "        client = storage.Client()  # will use ADC or GOOGLE_APPLICATION_CREDENTIALS\n",
    "        bucket = client.bucket(bucket_name)\n",
    "        if not bucket.exists():\n",
    "            logger.warning(\"Bucket %s does not appear to exist or is inaccessible.\", bucket_name)\n",
    "            # Still continue: bucket.exists() may require permissions; try upload anyway\n",
    "        for local_path in files:\n",
    "            blob_name = f\"{destination_prefix}/{local_path.name}\"\n",
    "            blob = bucket.blob(blob_name)\n",
    "            blob.upload_from_filename(str(local_path))\n",
    "            logger.info(\"Uploaded %s -> gs://%s/%s\", local_path.name, bucket_name, blob_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Python client upload failed: %s\", e)\n",
    "        return False\n",
    "\n",
    "def upload_with_gcloud_cli(bucket_name: str, files: List[Path], destination_prefix: str) -> bool:\n",
    "    \"\"\"\n",
    "    Fallback upload using `gcloud storage cp` (gcloud CLI must be installed + authenticated).\n",
    "    Returns True on success.\n",
    "    \"\"\"\n",
    "    logger.info(\"Attempting upload via gcloud CLI (fallback).\")\n",
    "    try:\n",
    "        for local_path in files:\n",
    "            dest = f\"gs://{bucket_name}/{destination_prefix}/{local_path.name}\"\n",
    "            cmd = [\"gcloud\", \"storage\", \"cp\", str(local_path), dest, \"--quiet\"]\n",
    "            logger.debug(\"Running CLI command: %s\", \" \".join(cmd))\n",
    "            completed = subprocess.run(cmd, capture_output=True, text=True, check=False)\n",
    "            if completed.returncode != 0:\n",
    "                logger.error(\"gcloud cp failed for %s: %s %s\", local_path, completed.stderr, completed.stdout)\n",
    "                return False\n",
    "            logger.info(\"gcloud cp succeeded for %s -> %s\", local_path.name, dest)\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"gcloud CLI not found. Install and authenticate gcloud or enable ADC.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logger.exception(\"gcloud CLI upload failed: %s\", e)\n",
    "        return False\n",
    "\n",
    "def upload_to_gcp_with_fallback(bucket_name: str, files: List[Path], base_prefix: str) -> bool:\n",
    "    \"\"\"\n",
    "    Try python client, then CLI fallback. Returns True on success.\n",
    "    \"\"\"\n",
    "    date_folder = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "    timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    prefix = f\"{base_prefix}/{date_folder}/{timestamp}\"\n",
    "    # try python client first\n",
    "    ok = upload_with_python_client(bucket_name, files, prefix)\n",
    "    if ok:\n",
    "        return True\n",
    "    # fallback to gcloud CLI\n",
    "    ok_cli = upload_with_gcloud_cli(bucket_name, files, prefix)\n",
    "    return ok_cli\n",
    "\n",
    "# ---------- Spread selection ----------\n",
    "def get_safe_value(row: pd.Series, name: str):\n",
    "    if name in row.index:\n",
    "        return row[name]\n",
    "    return None\n",
    "\n",
    "def select_spread_strikes(chain: pd.DataFrame, current_price: float, spread_type: str, expiration: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Minimal, robust selection for a 5-point width credit spread near-target.\n",
    "    Returns a dict or None.\n",
    "    \"\"\"\n",
    "    if chain.empty:\n",
    "        return None\n",
    "    base_cols = [\"strike\", \"lastPrice\", \"bid\", \"ask\", \"contractSymbol\"]\n",
    "    # normalize column names if present\n",
    "    for col in base_cols:\n",
    "        if col not in chain.columns:\n",
    "            chain[col] = np.nan\n",
    "\n",
    "    chain = chain.copy()\n",
    "    # Some vendors return floats as ints; ensure numeric\n",
    "    chain[\"strike\"] = pd.to_numeric(chain[\"strike\"], errors=\"coerce\")\n",
    "\n",
    "    greek_cols = [\"delta\", \"theta\", \"vega\"]\n",
    "    available_greeks = [c for c in greek_cols if c in chain.columns]\n",
    "\n",
    "    if spread_type == \"PUT_CREDIT\":\n",
    "        puts = chain[chain.get(\"side\", \"\") == \"put\"] if \"side\" in chain.columns else chain[chain.get(\"contractSymbol\", \"\").str.contains(\"PUT\", na=False)]\n",
    "        puts = puts.dropna(subset=[\"strike\"])\n",
    "        otm_puts = puts[puts[\"strike\"] < current_price]\n",
    "        if otm_puts.empty:\n",
    "            return None\n",
    "\n",
    "        # choose a sell strike ~3% below current price (closest)\n",
    "        target = current_price * 0.97\n",
    "        sell_row = otm_puts.iloc[(otm_puts[\"strike\"] - target).abs().argsort()[:1]]\n",
    "        if sell_row.empty:\n",
    "            return None\n",
    "        sell = sell_row.iloc[0]\n",
    "        # choose buy 5 points lower than sell\n",
    "        buy_candidates = otm_puts[otm_puts[\"strike\"] < sell[\"strike\"]]\n",
    "        if buy_candidates.empty:\n",
    "            return None\n",
    "        desired_buy = sell[\"strike\"] - 5.0\n",
    "        buy_row = buy_candidates.iloc[(buy_candidates[\"strike\"] - desired_buy).abs().argsort()[:1]]\n",
    "        if buy_row.empty:\n",
    "            return None\n",
    "        buy = buy_row.iloc[0]\n",
    "\n",
    "        mid_sell = safe_div(sell.get(\"bid\", np.nan) + sell.get(\"ask\", np.nan), 2, default=np.nan)\n",
    "        mid_buy = safe_div(buy.get(\"bid\", np.nan) + buy.get(\"ask\", np.nan), 2, default=np.nan)\n",
    "        premium = safe_div(mid_sell - mid_buy, 1, default=np.nan)\n",
    "\n",
    "        return {\n",
    "            \"type\": \"Put Credit Spread\",\n",
    "            \"expiration\": expiration,\n",
    "            \"sell_strike\": float(sell[\"strike\"]),\n",
    "            \"buy_strike\": float(buy[\"strike\"]),\n",
    "            \"mid_premium\": float(premium) if pd.notna(premium) else None,\n",
    "            \"max_profit\": round(float(premium * 100) if pd.notna(premium) else 0.0, 2),\n",
    "            \"max_loss\": round(float(abs(sell[\"strike\"] - buy[\"strike\"]) * 100 - (premium * 100)) if pd.notna(premium) else 0.0, 2),\n",
    "            \"delta_sell\": get_safe_value(sell, \"delta\"),\n",
    "            \"theta_sell\": get_safe_value(sell, \"theta\"),\n",
    "            \"vega_sell\": get_safe_value(sell, \"vega\"),\n",
    "        }\n",
    "\n",
    "    elif spread_type == \"CALL_CREDIT\":\n",
    "        calls = chain[chain.get(\"side\", \"\") == \"call\"] if \"side\" in chain.columns else chain[chain.get(\"contractSymbol\", \"\").str.contains(\"CALL\", na=False)]\n",
    "        calls = calls.dropna(subset=[\"strike\"])\n",
    "        otm_calls = calls[calls[\"strike\"] > current_price]\n",
    "        if otm_calls.empty:\n",
    "            return None\n",
    "        target = current_price * 1.03\n",
    "        sell_row = otm_calls.iloc[(otm_calls[\"strike\"] - target).abs().argsort()[:1]]\n",
    "        if sell_row.empty:\n",
    "            return None\n",
    "        sell = sell_row.iloc[0]\n",
    "        buy_candidates = otm_calls[otm_calls[\"strike\"] > sell[\"strike\"]]\n",
    "        if buy_candidates.empty:\n",
    "            return None\n",
    "        desired_buy = sell[\"strike\"] + 5.0\n",
    "        buy_row = buy_candidates.iloc[(buy_candidates[\"strike\"] - desired_buy).abs().argsort()[:1]]\n",
    "        if buy_row.empty:\n",
    "            return None\n",
    "        buy = buy_row.iloc[0]\n",
    "\n",
    "        mid_sell = safe_div(sell.get(\"bid\", np.nan) + sell.get(\"ask\", np.nan), 2, default=np.nan)\n",
    "        mid_buy = safe_div(buy.get(\"bid\", np.nan) + buy.get(\"ask\", np.nan), 2, default=np.nan)\n",
    "        premium = safe_div(mid_sell - mid_buy, 1, default=np.nan)\n",
    "\n",
    "        return {\n",
    "            \"type\": \"Call Credit Spread\",\n",
    "            \"expiration\": expiration,\n",
    "            \"sell_strike\": float(sell[\"strike\"]),\n",
    "            \"buy_strike\": float(buy[\"strike\"]),\n",
    "            \"mid_premium\": float(premium) if pd.notna(premium) else None,\n",
    "            \"max_profit\": round(float(premium * 100) if pd.notna(premium) else 0.0, 2),\n",
    "            \"max_loss\": round(float(abs(sell[\"strike\"] - buy[\"strike\"]) * 100 - (premium * 100)) if pd.notna(premium) else 0.0, 2),\n",
    "            \"delta_sell\": get_safe_value(sell, \"delta\"),\n",
    "            \"theta_sell\": get_safe_value(sell, \"theta\"),\n",
    "            \"vega_sell\": get_safe_value(sell, \"vega\"),\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# ---------- Save & report ----------\n",
    "def save_locally(data: Dict[str, Any], filename: str, local_dir: Path = LOCAL_SAVE_DIR) -> List[Path]:\n",
    "    \"\"\"\n",
    "    Save JSON and Markdown to local_dir and return list of saved Paths.\n",
    "    \"\"\"\n",
    "    local_dir.mkdir(parents=True, exist_ok=True)\n",
    "    json_filename = filename.replace(\".md\", \".json\")\n",
    "    json_path = local_dir / json_filename\n",
    "    md_path = local_dir / filename\n",
    "\n",
    "    saved_files = []\n",
    "    try:\n",
    "        with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, indent=2, default=str)\n",
    "        saved_files.append(json_path)\n",
    "        logger.info(\"Saved JSON: %s\", json_path)\n",
    "\n",
    "        with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(data[\"markdown_report\"])\n",
    "        saved_files.append(md_path)\n",
    "        logger.info(\"Saved Markdown: %s\", md_path)\n",
    "        return saved_files\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Local save failed: %s\", e)\n",
    "        return saved_files\n",
    "\n",
    "def build_markdown_report(ticker: str, indicators: Dict[str, Any], spreads: List[Dict[str, Any]]) -> str:\n",
    "    md = f\"# AI-Enhanced Credit Spread Analysis: {ticker}\\n\\n\"\n",
    "    md += f\"**Date:** {date.today().isoformat()}\\n\"\n",
    "    md += f\"**Reference Price:** ${indicators['Current_Price']:.2f}\\n\\n\"\n",
    "    md += \"## Technical Landscape (12 Indicators)\\n\"\n",
    "    for k, v in indicators.items():\n",
    "        if isinstance(v, float):\n",
    "            if math.isnan(v):\n",
    "                md += f\"- **{k}:** N/A\\n\"\n",
    "            else:\n",
    "                md += f\"- **{k}:** {v:.2f}\\n\"\n",
    "        else:\n",
    "            md += f\"- **{k}:** {v}\\n\"\n",
    "    md += \"\\n---\\n\\n\"\n",
    "    if not spreads:\n",
    "        md += \"_No spreads found / generated._\\n\\n\"\n",
    "    for spread in spreads:\n",
    "        md += f\"### {spread['type']} ({spread['expiration']})\\n\"\n",
    "        md += f\"**Strategy:** Sell ${spread['sell_strike']} / Buy ${spread['buy_strike']}\\n\\n\"\n",
    "        md += f\"**Est. Credit:** ${spread['max_profit']} | **Max Risk:** ${spread['max_loss']}\\n\\n\"\n",
    "        md += f\"**Analysis:**\\n\\n{spread.get('rationale', 'No rationale generated.')}\\n\\n\"\n",
    "        md += \"---\\n\\n\"\n",
    "    return md\n",
    "\n",
    "# ---------- Main analysis flow ----------\n",
    "def main(\n",
    "    ticker_symbol: str = TICKER,\n",
    "    days_of_history: int = DAYS_OF_HISTORY,\n",
    "    gcp_bucket: str = GCP_BUCKET,\n",
    "    mistral_api_key: str = MISTRAL_API_KEY,\n",
    "    mistral_model: str = MISTRAL_MODEL,\n",
    "):\n",
    "    logger.info(\"Starting analysis for %s\", ticker_symbol)\n",
    "\n",
    "    # Quick Mistral connectivity check\n",
    "    mistral_ok = quick_mistral_test(mistral_api_key, mistral_model) if mistral_api_key else False\n",
    "    if not mistral_ok and mistral_api_key:\n",
    "        logger.warning(\"Mistral connectivity test returned negative result; AI calls may fail.\")\n",
    "\n",
    "    # Fetch history (limit to days_of_history to be efficient)\n",
    "    try:\n",
    "        ticker = yf.Ticker(ticker_symbol)\n",
    "        # prefer a daily window; use 'period' when available\n",
    "        df = ticker.history(period=f\"{days_of_history}d\", auto_adjust=False)\n",
    "        if df.empty:\n",
    "            logger.error(\"No historical data returned for %s\", ticker_symbol)\n",
    "            return\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Failed fetching history: %s\", e)\n",
    "        return\n",
    "\n",
    "    # Calculate indicators\n",
    "    try:\n",
    "        indicators = calculate_technical_indicators(df)\n",
    "        logger.info(\"Indicators calculated. Current price: $%.2f\", indicators[\"Current_Price\"])\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Indicator calculation failed: %s\", e)\n",
    "        return\n",
    "\n",
    "    # Get option expirations\n",
    "    try:\n",
    "        available_expirations = ticker.options\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Could not fetch option expirations: %s\", e)\n",
    "        available_expirations = []\n",
    "\n",
    "    if not available_expirations:\n",
    "        logger.warning(\"No option expirations returned.\")\n",
    "        # Prepare a report and exit gracefully\n",
    "        filename = f\"{ticker_symbol}_spread_analysis_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.md\"\n",
    "        md = build_markdown_report(ticker_symbol, indicators, [])\n",
    "        complete_data = {\n",
    "            \"symbol\": ticker_symbol,\n",
    "            \"timestamp\": datetime.utcnow().isoformat(),\n",
    "            \"date\": date.today().isoformat(),\n",
    "            \"indicators\": indicators,\n",
    "            \"spreads\": [],\n",
    "            \"markdown_report\": md,\n",
    "        }\n",
    "        saved = save_locally(complete_data, filename)\n",
    "        if saved:\n",
    "            logger.info(\"Saved minimal report despite no options.\")\n",
    "        return\n",
    "\n",
    "    # Select expirations near target days\n",
    "    target_days = [14, 30, 45, 60, 90, 180]\n",
    "    chosen = []\n",
    "    for t in target_days:\n",
    "        target_date = date.today() + timedelta(days=t)\n",
    "        # available_expirations are strings like '2023-12-15'\n",
    "        try:\n",
    "            closest = min(available_expirations, key=lambda x: abs((date.fromisoformat(x) - target_date).days))\n",
    "            if closest not in chosen:\n",
    "                chosen.append(closest)\n",
    "        except Exception:\n",
    "            continue\n",
    "    chosen = chosen[:6]\n",
    "    logger.info(\"Selected expirations: %s\", chosen)\n",
    "\n",
    "    all_spreads: List[Dict[str, Any]] = []\n",
    "    api_rate_delay = 1.0  # friendly delay between potentially heavy API calls\n",
    "\n",
    "    for exp in chosen:\n",
    "        logger.info(\"Processing expiration: %s\", exp)\n",
    "        try:\n",
    "            chain = ticker.option_chain(exp)\n",
    "            calls = chain.calls.copy()\n",
    "            puts = chain.puts.copy()\n",
    "            calls[\"side\"] = \"call\"\n",
    "            puts[\"side\"] = \"put\"\n",
    "            full_chain = pd.concat([calls, puts], ignore_index=True, sort=False)\n",
    "\n",
    "            pcs = select_spread_strikes(full_chain, indicators[\"Current_Price\"], \"PUT_CREDIT\", exp)\n",
    "            if pcs:\n",
    "                # delay to avoid any rate limits\n",
    "                time.sleep(api_rate_delay)\n",
    "                pcs[\"rationale\"] = generate_ai_rationale(mistral_api_key, mistral_model, pcs, indicators) if mistral_api_key else \"Mistral API not configured.\"\n",
    "                all_spreads.append(pcs)\n",
    "\n",
    "            ccs = select_spread_strikes(full_chain, indicators[\"Current_Price\"], \"CALL_CREDIT\", exp)\n",
    "            if ccs:\n",
    "                time.sleep(api_rate_delay)\n",
    "                ccs[\"rationale\"] = generate_ai_rationale(mistral_api_key, mistral_model, ccs, indicators) if mistral_api_key else \"Mistral API not configured.\"\n",
    "                all_spreads.append(ccs)\n",
    "        except Exception as e:\n",
    "            logger.exception(\"Skipping expiration %s due to error: %s\", exp, e)\n",
    "            continue\n",
    "\n",
    "    # Generate markdown report\n",
    "    timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{ticker_symbol}_spread_analysis_{timestamp}.md\"\n",
    "    md_report = build_markdown_report(ticker_symbol, indicators, all_spreads)\n",
    "    complete_data = {\n",
    "        \"symbol\": ticker_symbol,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"date\": date.today().isoformat(),\n",
    "        \"indicators\": indicators,\n",
    "        \"spreads\": all_spreads,\n",
    "        \"markdown_report\": md_report,\n",
    "    }\n",
    "\n",
    "    # Save locally\n",
    "    saved_files = save_locally(complete_data, filename)\n",
    "    if not saved_files:\n",
    "        logger.error(\"Failed to save any local files. Aborting GCP upload.\")\n",
    "        return\n",
    "\n",
    "    # Attempt upload with fallback (python client -> gcloud CLI)\n",
    "    base_prefix = f\"options/{ticker_symbol}\"\n",
    "    upload_ok = upload_to_gcp_with_fallback(gcp_bucket, saved_files, base_prefix)\n",
    "    if upload_ok:\n",
    "        logger.info(\"Upload to GCP successful.\")\n",
    "    else:\n",
    "        logger.error(\"Upload to GCP failed (both python client & gcloud CLI). Please verify credentials and bucket permissions.\")\n",
    "\n",
    "    logger.info(\"Analysis complete for %s\", ticker_symbol)\n",
    "\n",
    "# ---------- CLI entrypoint ----------\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"AI-Enhanced Options Spread Analysis\")\n",
    "    parser.add_argument(\"--ticker\", type=str, default=TICKER, help=\"Ticker symbol\")\n",
    "    parser.add_argument(\"--history-days\", type=int, default=DAYS_OF_HISTORY, help=\"Days of historical data to fetch\")\n",
    "    parser.add_argument(\"--gcp-bucket\", type=str, default=GCP_BUCKET, help=\"GCP bucket name for uploads\")\n",
    "    parser.add_argument(\"--mistral-key\", type=str, default=os.getenv(\"MISTRAL_API_KEY\", \"\"), help=\"Mistral API key (env MISTRAL_API_KEY preferred)\")\n",
    "    parser.add_argument(\"--mistral-model\", type=str, default=MISTRAL_MODEL, help=\"Mistral model\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # pass provided args to main\n",
    "    main(\n",
    "        ticker_symbol=args.ticker,\n",
    "        days_of_history=args.history_days,\n",
    "        gcp_bucket=args.gcp_bucket,\n",
    "        mistral_api_key=args.mistral_key,\n",
    "        mistral_model=args.mistral_model,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin-ai1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
