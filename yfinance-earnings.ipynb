{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efcba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (0.2.65)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from yfinance) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from yfinance) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from yfinance) (4.3.8)\n",
      "Requirement already satisfied: pytz>=2022.5 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from yfinance) (2025.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from yfinance) (3.18.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from yfinance) (4.13.5)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from yfinance) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from yfinance) (5.29.4)\n",
      "Requirement already satisfied: websockets>=13.0 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from yfinance) (15.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.2)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from curl_cffi>=0.7->yfinance) (2025.4.26)\n",
      "Requirement already satisfied: pycparser in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2.4.0)\n",
      "Next earnings date: 2025-02-27\n",
      "                           EPS Estimate  Reported EPS  Surprise(%) Event Type\n",
      "Earnings Date                                                                \n",
      "2025-05-01 16:30:00-04:00          1.63          1.65         1.41   Earnings\n",
      "2025-02-27 12:00:00-05:00           NaN           NaN          NaN    Meeting\n",
      "2025-01-30 16:31:00-05:00          2.35          2.40         2.15   Earnings\n",
      "2024-10-31 16:31:00-04:00          1.60          1.64         2.35   Earnings\n",
      "2024-08-01 16:30:00-04:00          1.35          1.40         3.99   Earnings\n",
      "2024-05-02 16:31:00-04:00          1.50          1.53         1.97   Earnings\n",
      "2024-02-01 16:00:00-05:00          2.10          2.18         3.90   Earnings\n",
      "2023-11-02 16:30:00-04:00          1.39          1.46         4.92   Earnings\n",
      "2023-08-03 16:30:00-04:00          1.19          1.26         5.49   Earnings\n",
      "2023-05-04 16:30:00-04:00          1.43          1.52         6.03   Earnings\n"
     ]
    }
   ],
   "source": [
    "# !pip install yfinance --upgrade\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "# Pick a stock\n",
    "ticker = yf.Ticker(\"AAPL\")\n",
    "\n",
    "# Get upcoming and past earnings dates\n",
    "earnings_dates = ticker.get_earnings_dates(limit=10)\n",
    "\n",
    "future_earnings = earnings_dates[earnings_dates[\"Reported EPS\"].isna()]\n",
    "next_earnings = future_earnings.index[0]\n",
    "\n",
    "print(\"Next earnings date:\", next_earnings.date())\n",
    "\n",
    "print(earnings_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89949502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting comprehensive stock data extraction...\n",
      "📊 Target stock: AAPL\n",
      "\n",
      "=== Extracting data for AAPL ===\n",
      "✓ Saved AAPL_basic_info.csv (1 records)\n",
      "✓ Saved AAPL_history_1mo.csv (22 records)\n",
      "✓ Saved AAPL_history_3mo.csv (63 records)\n",
      "✓ Saved AAPL_history_6mo.csv (127 records)\n",
      "✓ Saved AAPL_history_1y.csv (250 records)\n",
      "✓ Saved AAPL_history_2y.csv (502 records)\n",
      "✓ Saved AAPL_history_5y.csv (1256 records)\n",
      "✓ Saved AAPL_history_10y.csv (2515 records)\n",
      "✓ Saved AAPL_history_ytd.csv (174 records)\n",
      "✓ Saved AAPL_history_max.csv (11279 records)\n",
      "✓ Saved AAPL_earnings_dates.csv (40 records)\n",
      "✗ No data for quarterly_earnings.csv\n",
      "✗ No data for yearly_earnings.csv\n",
      "✓ Saved AAPL_financials.csv (39 records)\n",
      "✓ Saved AAPL_quarterly_financials.csv (33 records)\n",
      "✓ Saved AAPL_balance_sheet.csv (68 records)\n",
      "✓ Saved AAPL_quarterly_balance_sheet.csv (65 records)\n",
      "✓ Saved AAPL_cashflow.csv (53 records)\n",
      "✓ Saved AAPL_quarterly_cashflow.csv (46 records)\n",
      "✓ Saved AAPL_dividends.csv (88 records)\n",
      "✓ Saved AAPL_splits.csv (5 records)\n",
      "Available options dates: 20\n",
      "✓ Saved AAPL_options_calls_2025-09-19.csv (81 records)\n",
      "✓ Saved AAPL_options_puts_2025-09-19.csv (78 records)\n",
      "✓ Saved AAPL_options_calls_2025-09-26.csv (43 records)\n",
      "✓ Saved AAPL_options_puts_2025-09-26.csv (35 records)\n",
      "✓ Saved AAPL_options_calls_2025-10-03.csv (32 records)\n",
      "✓ Saved AAPL_options_puts_2025-10-03.csv (29 records)\n",
      "✓ Saved AAPL_institutional_holders.csv (10 records)\n",
      "✓ Saved AAPL_major_holders.csv (4 records)\n",
      "✓ Saved AAPL_mutual_fund_holders.csv (10 records)\n",
      "✓ Saved AAPL_analyst_recommendations.csv (4 records)\n",
      "✓ Saved AAPL_recommendations_summary.csv (4 records)\n",
      "✗ Error getting analyst price target: 'Ticker' object has no attribute 'analyst_price_target'\n",
      "✓ Saved AAPL_sustainability_esg.csv (36 records)\n",
      "✓ Saved AAPL_insider_transactions.csv (79 records)\n",
      "✓ Saved AAPL_insider_purchases.csv (7 records)\n",
      "✓ Saved AAPL_insider_roster_holders.csv (10 records)\n",
      "✓ Saved AAPL_news.csv (10 records)\n",
      "✗ Error saving calendar_events.csv: 'dict' object has no attribute 'empty'\n",
      "✓ Saved AAPL_isin.csv (1 records)\n",
      "✓ Saved AAPL_next_earnings_date.csv (1 records)\n",
      "\n",
      "🎯 Next earnings date: 2025-02-27\n",
      "\n",
      "✅ Completed data extraction for AAPL\n",
      "📁 All files saved in 'AAPL_data' directory\n",
      "\n",
      "==================================================\n",
      "📈 EXTRACTION COMPLETE!\n",
      "==================================================\n",
      "Check the 'AAPL_data' folder for all CSV files\n",
      "\n",
      "Files may include:\n",
      "- Basic company info\n",
      "- Historical prices (multiple timeframes)\n",
      "- Financial statements (annual & quarterly)\n",
      "- Earnings data\n",
      "- Dividend & split history\n",
      "- Options data\n",
      "- Analyst recommendations\n",
      "- Institutional holdings\n",
      "- Insider trading\n",
      "- ESG/Sustainability data\n",
      "- Recent news\n",
      "- And more!\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def safe_to_csv(data, filename, ticker_symbol):\n",
    "    \"\"\"Safely convert data to CSV with error handling\"\"\"\n",
    "    try:\n",
    "        if data is not None and not data.empty:\n",
    "            # Create filename with ticker symbol\n",
    "            full_filename = f\"{ticker_symbol}_{filename}\"\n",
    "            data.to_csv(full_filename)\n",
    "            print(f\"✓ Saved {full_filename} ({len(data)} records)\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"✗ No data for {filename}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error saving {filename}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def extract_all_stock_data(symbol):\n",
    "    \"\"\"Extract comprehensive stock data from yfinance API\"\"\"\n",
    "    print(f\"\\n=== Extracting data for {symbol} ===\")\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    \n",
    "    # Create directory for the stock\n",
    "    os.makedirs(f\"{symbol}_data\", exist_ok=True)\n",
    "    os.chdir(f\"{symbol}_data\")\n",
    "    \n",
    "    # 1. Basic Info\n",
    "    try:\n",
    "        info = ticker.info\n",
    "        if info:\n",
    "            info_df = pd.DataFrame([info])\n",
    "            safe_to_csv(info_df, \"basic_info.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting basic info: {e}\")\n",
    "    \n",
    "    # 2. Historical Data (multiple periods)\n",
    "    periods = [\"1mo\", \"3mo\", \"6mo\", \"1y\", \"2y\", \"5y\", \"10y\", \"ytd\", \"max\"]\n",
    "    for period in periods:\n",
    "        try:\n",
    "            hist = ticker.history(period=period)\n",
    "            if not hist.empty:\n",
    "                safe_to_csv(hist, f\"history_{period}.csv\", symbol)\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error getting {period} history: {e}\")\n",
    "    \n",
    "    # 3. Earnings Data\n",
    "    try:\n",
    "        earnings = ticker.get_earnings_dates(limit=40)  # More earnings dates\n",
    "        safe_to_csv(earnings, \"earnings_dates.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting earnings dates: {e}\")\n",
    "    \n",
    "    try:\n",
    "        quarterly_earnings = ticker.quarterly_earnings\n",
    "        safe_to_csv(quarterly_earnings, \"quarterly_earnings.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting quarterly earnings: {e}\")\n",
    "    \n",
    "    try:\n",
    "        yearly_earnings = ticker.earnings\n",
    "        safe_to_csv(yearly_earnings, \"yearly_earnings.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting yearly earnings: {e}\")\n",
    "    \n",
    "    # 4. Financial Statements\n",
    "    try:\n",
    "        financials = ticker.financials\n",
    "        safe_to_csv(financials, \"financials.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting financials: {e}\")\n",
    "    \n",
    "    try:\n",
    "        quarterly_financials = ticker.quarterly_financials\n",
    "        safe_to_csv(quarterly_financials, \"quarterly_financials.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting quarterly financials: {e}\")\n",
    "    \n",
    "    try:\n",
    "        balance_sheet = ticker.balance_sheet\n",
    "        safe_to_csv(balance_sheet, \"balance_sheet.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting balance sheet: {e}\")\n",
    "    \n",
    "    try:\n",
    "        quarterly_balance_sheet = ticker.quarterly_balance_sheet\n",
    "        safe_to_csv(quarterly_balance_sheet, \"quarterly_balance_sheet.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting quarterly balance sheet: {e}\")\n",
    "    \n",
    "    try:\n",
    "        cashflow = ticker.cashflow\n",
    "        safe_to_csv(cashflow, \"cashflow.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting cashflow: {e}\")\n",
    "    \n",
    "    try:\n",
    "        quarterly_cashflow = ticker.quarterly_cashflow\n",
    "        safe_to_csv(quarterly_cashflow, \"quarterly_cashflow.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting quarterly cashflow: {e}\")\n",
    "    \n",
    "    # 5. Dividend and Split Data\n",
    "    try:\n",
    "        dividends = ticker.dividends\n",
    "        if not dividends.empty:\n",
    "            safe_to_csv(dividends.to_frame(), \"dividends.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting dividends: {e}\")\n",
    "    \n",
    "    try:\n",
    "        splits = ticker.splits\n",
    "        if not splits.empty:\n",
    "            safe_to_csv(splits.to_frame(), \"splits.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting splits: {e}\")\n",
    "    \n",
    "    # 6. Options Data\n",
    "    try:\n",
    "        options_dates = ticker.options\n",
    "        if options_dates:\n",
    "            print(f\"Available options dates: {len(options_dates)}\")\n",
    "            # Get options for first few expiration dates\n",
    "            for i, date in enumerate(options_dates[:3]):  # Limit to first 3 dates\n",
    "                try:\n",
    "                    options = ticker.option_chain(date)\n",
    "                    if hasattr(options, 'calls') and not options.calls.empty:\n",
    "                        safe_to_csv(options.calls, f\"options_calls_{date}.csv\", symbol)\n",
    "                    if hasattr(options, 'puts') and not options.puts.empty:\n",
    "                        safe_to_csv(options.puts, f\"options_puts_{date}.csv\", symbol)\n",
    "                except Exception as e:\n",
    "                    print(f\"✗ Error getting options for {date}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting options: {e}\")\n",
    "    \n",
    "    # 7. Institutional Holders\n",
    "    try:\n",
    "        institutional_holders = ticker.institutional_holders\n",
    "        safe_to_csv(institutional_holders, \"institutional_holders.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting institutional holders: {e}\")\n",
    "    \n",
    "    try:\n",
    "        major_holders = ticker.major_holders\n",
    "        safe_to_csv(major_holders, \"major_holders.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting major holders: {e}\")\n",
    "    \n",
    "    try:\n",
    "        mutual_fund_holders = ticker.mutualfund_holders\n",
    "        safe_to_csv(mutual_fund_holders, \"mutual_fund_holders.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting mutual fund holders: {e}\")\n",
    "    \n",
    "    # 8. Analyst Data\n",
    "    try:\n",
    "        recommendations = ticker.recommendations\n",
    "        safe_to_csv(recommendations, \"analyst_recommendations.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting recommendations: {e}\")\n",
    "    \n",
    "    try:\n",
    "        recommendations_summary = ticker.recommendations_summary\n",
    "        safe_to_csv(recommendations_summary, \"recommendations_summary.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting recommendations summary: {e}\")\n",
    "    \n",
    "    try:\n",
    "        analyst_price_target = ticker.analyst_price_target\n",
    "        if analyst_price_target:\n",
    "            target_df = pd.DataFrame([analyst_price_target])\n",
    "            safe_to_csv(target_df, \"analyst_price_target.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting analyst price target: {e}\")\n",
    "    \n",
    "    # 9. Sustainability/ESG Data\n",
    "    try:\n",
    "        sustainability = ticker.sustainability\n",
    "        safe_to_csv(sustainability, \"sustainability_esg.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting sustainability data: {e}\")\n",
    "    \n",
    "    # 10. Insider Trading\n",
    "    try:\n",
    "        insider_transactions = ticker.insider_transactions\n",
    "        safe_to_csv(insider_transactions, \"insider_transactions.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting insider transactions: {e}\")\n",
    "    \n",
    "    try:\n",
    "        insider_purchases = ticker.insider_purchases\n",
    "        safe_to_csv(insider_purchases, \"insider_purchases.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting insider purchases: {e}\")\n",
    "    \n",
    "    try:\n",
    "        insider_roster_holders = ticker.insider_roster_holders\n",
    "        safe_to_csv(insider_roster_holders, \"insider_roster_holders.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting insider roster holders: {e}\")\n",
    "    \n",
    "    # 11. News\n",
    "    try:\n",
    "        news = ticker.news\n",
    "        if news:\n",
    "            news_df = pd.DataFrame(news)\n",
    "            safe_to_csv(news_df, \"news.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting news: {e}\")\n",
    "    \n",
    "    # 12. Calendar Events\n",
    "    try:\n",
    "        calendar = ticker.calendar\n",
    "        safe_to_csv(calendar, \"calendar_events.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting calendar: {e}\")\n",
    "    \n",
    "    # 13. ISIN\n",
    "    try:\n",
    "        isin = ticker.isin\n",
    "        if isin:\n",
    "            isin_df = pd.DataFrame([{\"ISIN\": isin}])\n",
    "            safe_to_csv(isin_df, \"isin.csv\", symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting ISIN: {e}\")\n",
    "    \n",
    "    # Special: Next earnings date (from your original code)\n",
    "    try:\n",
    "        earnings_dates = ticker.get_earnings_dates(limit=10)\n",
    "        if not earnings_dates.empty:\n",
    "            future_earnings = earnings_dates[earnings_dates[\"Reported EPS\"].isna()]\n",
    "            if not future_earnings.empty:\n",
    "                next_earnings = future_earnings.index[0]\n",
    "                next_earnings_df = pd.DataFrame([{\n",
    "                    \"Next_Earnings_Date\": next_earnings.date(),\n",
    "                    \"Extracted_On\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                }])\n",
    "                safe_to_csv(next_earnings_df, \"next_earnings_date.csv\", symbol)\n",
    "                print(f\"\\n🎯 Next earnings date: {next_earnings.date()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting next earnings date: {e}\")\n",
    "    \n",
    "    # Go back to parent directory\n",
    "    os.chdir(\"..\")\n",
    "    print(f\"\\n✅ Completed data extraction for {symbol}\")\n",
    "    print(f\"📁 All files saved in '{symbol}_data' directory\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change this to any stock symbol\n",
    "    STOCK_SYMBOL = \"AAPL\"\n",
    "    \n",
    "    # Install required package (uncomment if needed)\n",
    "    # !pip install yfinance --upgrade\n",
    "    \n",
    "    print(\"🚀 Starting comprehensive stock data extraction...\")\n",
    "    print(f\"📊 Target stock: {STOCK_SYMBOL}\")\n",
    "    \n",
    "    extract_all_stock_data(STOCK_SYMBOL)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"📈 EXTRACTION COMPLETE!\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Check the '{STOCK_SYMBOL}_data' folder for all CSV files\")\n",
    "    print(\"\\nFiles may include:\")\n",
    "    print(\"- Basic company info\")\n",
    "    print(\"- Historical prices (multiple timeframes)\")\n",
    "    print(\"- Financial statements (annual & quarterly)\")\n",
    "    print(\"- Earnings data\")\n",
    "    print(\"- Dividend & split history\")\n",
    "    print(\"- Options data\")\n",
    "    print(\"- Analyst recommendations\")\n",
    "    print(\"- Institutional holdings\")\n",
    "    print(\"- Insider trading\")\n",
    "    print(\"- ESG/Sustainability data\")\n",
    "    print(\"- Recent news\")\n",
    "    print(\"- And more!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8347b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting streamlined technical analysis...\n",
      "📊 Target stock: AAPL\n",
      "\n",
      "=== Creating consolidated dataset for AAPL ===\n",
      "📈 Fetching historical data and calculating indicators...\n",
      "✅ Saved AAPL_technical_analysis.csv (501 records)\n",
      "🔍 Generating recent signals...\n",
      "✅ Saved AAPL_recent_signals.csv (12 signals)\n",
      "📊 Analyzing options data...\n",
      "✅ Saved AAPL_options_analysis.csv (175 records)\n",
      "📋 Extracting key fundamentals...\n",
      "✅ Saved AAPL_key_fundamentals.csv\n",
      "📄 Generating summary report...\n",
      "✅ Saved AAPL_summary.csv\n",
      "\n",
      "🎯 ANALYSIS COMPLETE for AAPL\n",
      "📁 Created files:\n",
      "  1. technical_analysis.csv - Full price history with all indicators\n",
      "  2. recent_signals.csv - Trading signals from last 30 days\n",
      "  3. options_analysis.csv - Options data with IV analysis\n",
      "  4. key_fundamentals.csv - Important company metrics\n",
      "  5. summary.csv - Current snapshot\n",
      "\n",
      "============================================================\n",
      "📈 STREAMLINED ANALYSIS COMPLETE!\n",
      "============================================================\n",
      "This approach gives you:\n",
      "✅ Much fewer files (5 vs 20+)\n",
      "✅ All technical indicators calculated\n",
      "✅ Trading signals identified\n",
      "✅ Options analysis with IV data\n",
      "✅ Key fundamentals consolidated\n",
      "✅ Ready for further analysis/backtesting\n"
     ]
    }
   ],
   "source": [
    "# more concise some values not there\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def calculate_ema(data, period):\n",
    "    \"\"\"Calculate Exponential Moving Average\"\"\"\n",
    "    return data.ewm(span=period).mean()\n",
    "\n",
    "def calculate_rsi(data, period=14):\n",
    "    \"\"\"Calculate Relative Strength Index\"\"\"\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def calculate_macd(data, fast=12, slow=26, signal=9):\n",
    "    \"\"\"Calculate MACD\"\"\"\n",
    "    ema_fast = calculate_ema(data, fast)\n",
    "    ema_slow = calculate_ema(data, slow)\n",
    "    macd_line = ema_fast - ema_slow\n",
    "    signal_line = calculate_ema(macd_line, signal)\n",
    "    histogram = macd_line - signal_line\n",
    "    return macd_line, signal_line, histogram\n",
    "\n",
    "def detect_crossovers(fast_ma, slow_ma):\n",
    "    \"\"\"Detect EMA crossovers\"\"\"\n",
    "    crossovers = []\n",
    "    for i in range(1, len(fast_ma)):\n",
    "        if pd.isna(fast_ma.iloc[i-1]) or pd.isna(slow_ma.iloc[i-1]):\n",
    "            continue\n",
    "        if fast_ma.iloc[i-1] <= slow_ma.iloc[i-1] and fast_ma.iloc[i] > slow_ma.iloc[i]:\n",
    "            crossovers.append(('bullish', fast_ma.index[i]))\n",
    "        elif fast_ma.iloc[i-1] >= slow_ma.iloc[i-1] and fast_ma.iloc[i] < slow_ma.iloc[i]:\n",
    "            crossovers.append(('bearish', fast_ma.index[i]))\n",
    "    return crossovers\n",
    "\n",
    "def analyze_options_data(ticker, symbol):\n",
    "    \"\"\"Analyze options for IV changes and delta analysis\"\"\"\n",
    "    try:\n",
    "        options_dates = ticker.options[:3]  # First 3 expiration dates\n",
    "        all_options = []\n",
    "        \n",
    "        for date in options_dates:\n",
    "            try:\n",
    "                chain = ticker.option_chain(date)\n",
    "                \n",
    "                # Process calls\n",
    "                calls = chain.calls.copy()\n",
    "                calls['type'] = 'call'\n",
    "                calls['expiration'] = date\n",
    "                calls['days_to_expiry'] = (pd.to_datetime(date) - pd.Timestamp.now()).days\n",
    "                \n",
    "                # Process puts  \n",
    "                puts = chain.puts.copy()\n",
    "                puts['type'] = 'put'\n",
    "                puts['expiration'] = date\n",
    "                puts['days_to_expiry'] = (pd.to_datetime(date) - pd.Timestamp.now()).days\n",
    "                \n",
    "                # Combine and filter for liquid options\n",
    "                options = pd.concat([calls, puts])\n",
    "                options = options[options['volume'] > 10]  # Only liquid options\n",
    "                \n",
    "                # Calculate additional metrics\n",
    "                if 'impliedVolatility' in options.columns:\n",
    "                    options['iv_rank'] = options['impliedVolatility'].rank(pct=True)\n",
    "                    options['high_iv'] = options['impliedVolatility'] > options['impliedVolatility'].quantile(0.8)\n",
    "                \n",
    "                all_options.append(options)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing options for {date}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if all_options:\n",
    "            combined_options = pd.concat(all_options, ignore_index=True)\n",
    "            # Focus on most relevant columns\n",
    "            key_columns = ['strike', 'lastPrice', 'bid', 'ask', 'volume', 'openInterest', \n",
    "                          'impliedVolatility', 'delta', 'type', 'expiration', 'days_to_expiry', \n",
    "                          'iv_rank', 'high_iv']\n",
    "            available_columns = [col for col in key_columns if col in combined_options.columns]\n",
    "            return combined_options[available_columns]\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing options: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def create_consolidated_dataset(symbol):\n",
    "    \"\"\"Create consolidated dataset with technical indicators\"\"\"\n",
    "    print(f\"\\n=== Creating consolidated dataset for {symbol} ===\")\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    \n",
    "    # 1. CORE DATASET: Historical data with technical indicators\n",
    "    print(\"📈 Fetching historical data and calculating indicators...\")\n",
    "    hist = ticker.history(period=\"2y\")  # 2 years of data for good indicator calculation\n",
    "    \n",
    "    if hist.empty:\n",
    "        print(\"❌ No historical data available\")\n",
    "        return\n",
    "    \n",
    "    # Calculate technical indicators\n",
    "    hist['EMA_10'] = calculate_ema(hist['Close'], 10)\n",
    "    hist['EMA_20'] = calculate_ema(hist['Close'], 20)\n",
    "    hist['EMA_50'] = calculate_ema(hist['Close'], 50)\n",
    "    hist['SMA_20'] = hist['Close'].rolling(window=20).mean()\n",
    "    hist['SMA_50'] = hist['Close'].rolling(window=50).mean()\n",
    "    \n",
    "    # RSI\n",
    "    hist['RSI'] = calculate_rsi(hist['Close'])\n",
    "    hist['RSI_Oversold'] = hist['RSI'] < 30\n",
    "    hist['RSI_Overbought'] = hist['RSI'] > 70\n",
    "    \n",
    "    # MACD\n",
    "    macd, macd_signal, macd_hist = calculate_macd(hist['Close'])\n",
    "    hist['MACD'] = macd\n",
    "    hist['MACD_Signal'] = macd_signal\n",
    "    hist['MACD_Histogram'] = macd_hist\n",
    "    hist['MACD_Bullish'] = (hist['MACD'] > hist['MACD_Signal']) & (hist['MACD'].shift(1) <= hist['MACD_Signal'].shift(1))\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    hist['BB_Middle'] = hist['SMA_20']\n",
    "    bb_std = hist['Close'].rolling(window=20).std()\n",
    "    hist['BB_Upper'] = hist['BB_Middle'] + (bb_std * 2)\n",
    "    hist['BB_Lower'] = hist['BB_Middle'] - (bb_std * 2)\n",
    "    hist['BB_Squeeze'] = (hist['BB_Upper'] - hist['BB_Lower']) / hist['BB_Middle'] < 0.1\n",
    "    \n",
    "    # Volume analysis\n",
    "    hist['Volume_MA'] = hist['Volume'].rolling(window=20).mean()\n",
    "    hist['Volume_Spike'] = hist['Volume'] > (hist['Volume_MA'] * 2)\n",
    "    \n",
    "    # Price change analysis\n",
    "    hist['Daily_Return'] = hist['Close'].pct_change()\n",
    "    hist['Volatility_20d'] = hist['Daily_Return'].rolling(window=20).std() * np.sqrt(252)\n",
    "    hist['Large_Move'] = abs(hist['Daily_Return']) > hist['Daily_Return'].rolling(window=252).std() * 2\n",
    "    \n",
    "    # EMA crossover signals\n",
    "    hist['EMA_10_20_Bull'] = (hist['EMA_10'] > hist['EMA_20']) & (hist['EMA_10'].shift(1) <= hist['EMA_20'].shift(1))\n",
    "    hist['EMA_10_20_Bear'] = (hist['EMA_10'] < hist['EMA_20']) & (hist['EMA_10'].shift(1) >= hist['EMA_20'].shift(1))\n",
    "    hist['EMA_20_50_Bull'] = (hist['EMA_20'] > hist['EMA_50']) & (hist['EMA_20'].shift(1) <= hist['EMA_50'].shift(1))\n",
    "    hist['EMA_20_50_Bear'] = (hist['EMA_20'] < hist['EMA_50']) & (hist['EMA_20'].shift(1) >= hist['EMA_50'].shift(1))\n",
    "    \n",
    "    # Support/Resistance levels (simplified)\n",
    "    hist['Price_Near_High'] = hist['Close'] > (hist['High'].rolling(window=20).max() * 0.98)\n",
    "    hist['Price_Near_Low'] = hist['Close'] < (hist['Low'].rolling(window=20).min() * 1.02)\n",
    "    \n",
    "    hist.to_csv(f\"{symbol}_technical_analysis.csv\")\n",
    "    print(f\"✅ Saved {symbol}_technical_analysis.csv ({len(hist)} records)\")\n",
    "    \n",
    "    # 2. SUMMARY SIGNALS: Recent signals and alerts\n",
    "    print(\"🔍 Generating recent signals...\")\n",
    "    recent_data = hist.tail(30)  # Last 30 days\n",
    "    \n",
    "    signals = []\n",
    "    \n",
    "    # Recent crossovers\n",
    "    for i, row in recent_data.iterrows():\n",
    "        if row['EMA_10_20_Bull']:\n",
    "            signals.append({'Date': i, 'Signal': 'EMA_10_20_Bullish_Crossover', 'Value': row['Close'], 'Strength': 'Medium'})\n",
    "        if row['EMA_10_20_Bear']:\n",
    "            signals.append({'Date': i, 'Signal': 'EMA_10_20_Bearish_Crossover', 'Value': row['Close'], 'Strength': 'Medium'})\n",
    "        if row['EMA_20_50_Bull']:\n",
    "            signals.append({'Date': i, 'Signal': 'EMA_20_50_Bullish_Crossover', 'Value': row['Close'], 'Strength': 'Strong'})\n",
    "        if row['EMA_20_50_Bear']:\n",
    "            signals.append({'Date': i, 'Signal': 'EMA_20_50_Bearish_Crossover', 'Value': row['Close'], 'Strength': 'Strong'})\n",
    "        if row['RSI_Oversold']:\n",
    "            signals.append({'Date': i, 'Signal': 'RSI_Oversold', 'Value': row['RSI'], 'Strength': 'Medium'})\n",
    "        if row['RSI_Overbought']:\n",
    "            signals.append({'Date': i, 'Signal': 'RSI_Overbought', 'Value': row['RSI'], 'Strength': 'Medium'})\n",
    "        if row['Volume_Spike']:\n",
    "            signals.append({'Date': i, 'Signal': 'Volume_Spike', 'Value': row['Volume'], 'Strength': 'High'})\n",
    "        if row['Large_Move']:\n",
    "            signals.append({'Date': i, 'Signal': 'Large_Price_Move', 'Value': row['Daily_Return']*100, 'Strength': 'High'})\n",
    "        if row['MACD_Bullish']:\n",
    "            signals.append({'Date': i, 'Signal': 'MACD_Bullish_Crossover', 'Value': row['MACD'], 'Strength': 'Medium'})\n",
    "    \n",
    "    if signals:\n",
    "        signals_df = pd.DataFrame(signals)\n",
    "        signals_df.to_csv(f\"{symbol}_recent_signals.csv\", index=False)\n",
    "        print(f\"✅ Saved {symbol}_recent_signals.csv ({len(signals_df)} signals)\")\n",
    "    \n",
    "    # 3. OPTIONS ANALYSIS (if available)\n",
    "    print(\"📊 Analyzing options data...\")\n",
    "    options_data = analyze_options_data(ticker, symbol)\n",
    "    if options_data is not None and not options_data.empty:\n",
    "        options_data.to_csv(f\"{symbol}_options_analysis.csv\", index=False)\n",
    "        print(f\"✅ Saved {symbol}_options_analysis.csv ({len(options_data)} records)\")\n",
    "    \n",
    "    # 4. KEY FUNDAMENTALS (single consolidated file)\n",
    "    print(\"📋 Extracting key fundamentals...\")\n",
    "    fundamentals = {}\n",
    "    \n",
    "    try:\n",
    "        info = ticker.info\n",
    "        if info:\n",
    "            key_metrics = [\n",
    "                'marketCap', 'enterpriseValue', 'trailingPE', 'forwardPE', 'pegRatio',\n",
    "                'priceToBook', 'priceToSalesTrailing12Months', 'enterpriseToRevenue',\n",
    "                'beta', '52WeekChange', 'dividendYield', 'payoutRatio',\n",
    "                'trailingEps', 'forwardEps', 'bookValue', 'priceToBook',\n",
    "                'returnOnAssets', 'returnOnEquity', 'revenueGrowth', 'earningsGrowth',\n",
    "                'currentRatio', 'debtToEquity', 'freeCashflow', 'operatingCashflow'\n",
    "            ]\n",
    "            \n",
    "            for metric in key_metrics:\n",
    "                if metric in info:\n",
    "                    fundamentals[metric] = info[metric]\n",
    "            \n",
    "        # Add recent price metrics\n",
    "        current_price = hist['Close'][-1]\n",
    "        fundamentals['current_price'] = current_price\n",
    "        fundamentals['sma_20'] = hist['SMA_20'][-1]\n",
    "        fundamentals['sma_50'] = hist['SMA_50'][-1]\n",
    "        fundamentals['rsi'] = hist['RSI'][-1]\n",
    "        fundamentals['volume_avg_20d'] = hist['Volume_MA'][-1]\n",
    "        fundamentals['volatility_20d'] = hist['Volatility_20d'][-1]\n",
    "        \n",
    "        # Next earnings\n",
    "        try:\n",
    "            earnings_dates = ticker.get_earnings_dates(limit=5)\n",
    "            if not earnings_dates.empty:\n",
    "                future_earnings = earnings_dates[earnings_dates[\"Reported EPS\"].isna()]\n",
    "                if not future_earnings.empty:\n",
    "                    fundamentals['next_earnings_date'] = str(future_earnings.index[0].date())\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        if fundamentals:\n",
    "            fund_df = pd.DataFrame([fundamentals])\n",
    "            fund_df.to_csv(f\"{symbol}_key_fundamentals.csv\", index=False)\n",
    "            print(f\"✅ Saved {symbol}_key_fundamentals.csv\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error extracting fundamentals: {e}\")\n",
    "    \n",
    "    # 5. SUMMARY REPORT\n",
    "    print(\"📄 Generating summary report...\")\n",
    "    \n",
    "    latest = hist.iloc[-1]\n",
    "    summary = {\n",
    "        'Symbol': symbol,\n",
    "        'Date': str(latest.name.date()),\n",
    "        'Current_Price': latest['Close'],\n",
    "        'Daily_Change_Pct': latest['Daily_Return'] * 100,\n",
    "        'RSI': latest['RSI'],\n",
    "        'EMA_10': latest['EMA_10'],\n",
    "        'EMA_20': latest['EMA_20'],\n",
    "        'EMA_50': latest['EMA_50'],\n",
    "        'Volume_vs_Avg': latest['Volume'] / latest['Volume_MA'] if not pd.isna(latest['Volume_MA']) else None,\n",
    "        'Volatility_20d': latest['Volatility_20d'],\n",
    "        'Days_Since_EMA_Cross': None,  # Could be calculated\n",
    "        'Recent_Signals_Count': len(signals) if signals else 0,\n",
    "        'Analysis_Date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame([summary])\n",
    "    summary_df.to_csv(f\"{symbol}_summary.csv\", index=False)\n",
    "    print(f\"✅ Saved {symbol}_summary.csv\")\n",
    "    \n",
    "    print(f\"\\n🎯 ANALYSIS COMPLETE for {symbol}\")\n",
    "    print(\"📁 Created files:\")\n",
    "    print(\"  1. technical_analysis.csv - Full price history with all indicators\")\n",
    "    print(\"  2. recent_signals.csv - Trading signals from last 30 days\") \n",
    "    print(\"  3. options_analysis.csv - Options data with IV analysis\")\n",
    "    print(\"  4. key_fundamentals.csv - Important company metrics\")\n",
    "    print(\"  5. summary.csv - Current snapshot\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    STOCK_SYMBOL = \"AAPL\"  # Change this to any stock symbol\n",
    "    \n",
    "    print(\"🚀 Starting streamlined technical analysis...\")\n",
    "    print(f\"📊 Target stock: {STOCK_SYMBOL}\")\n",
    "    \n",
    "    create_consolidated_dataset(STOCK_SYMBOL)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"📈 STREAMLINED ANALYSIS COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"This approach gives you:\")\n",
    "    print(\"✅ Much fewer files (5 vs 20+)\")\n",
    "    print(\"✅ All technical indicators calculated\")\n",
    "    print(\"✅ Trading signals identified\") \n",
    "    print(\"✅ Options analysis with IV data\")\n",
    "    print(\"✅ Key fundamentals consolidated\")\n",
    "    print(\"✅ Ready for further analysis/backtesting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd08803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV Q&A Answer:\n",
      " \"The key to understanding the value of a new technology in the context of the entire system lies in the way it works on different elements of the system.\"\n",
      "\n",
      "The text was written by a scientist who has knowledge and expertise in the field of technology and its application within a system. The author presents their analysis and thoughts about the significance of a new technology for the entire system, focusing on its functionality and impact on various aspects of the system. They emphasize that understanding the value of the technology requires an examination of how it interacts with different parts of the system and its effects on those components.\n",
      "\n",
      "The statement highlights the importance of considering the context and application of the new technology in order to fully comprehend its value within the broader framework of the system. The author's perspective showcases their ability to think critically about the subject and provide a comprehensive understanding of the technology's role and significance within the system.\n",
      "\n",
      "In summary, the text emphasizes the need for a comprehensive analysis and evaluation of the new technology within the context of the entire system to truly grasp its value and potential impact on different aspects. The author demonstrates their ability to think deeply about the topic by considering various elements of the system that are affected by the technology. This approach allows for a deeper understanding of the technology's role and significance in the larger framework, ultimately leading to a more well-rounded evaluation of its overall value.\n",
      "\n",
      "Overall, this passage serves as a valuable resource for those interested in understanding the importance of analyzing new technologies within the system they're part of the system and how they can be utilized effectively. The text provides insights into this aspect of the system and highlights the significance of this technology by discussing its application in different areas.\n",
      "CSV files not found — run your crossover detection script first.\n"
     ]
    }
   ],
   "source": [
    "# uses Dolphin\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import json\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# ==================================================\n",
    "# OLLAMA HELPER\n",
    "# ==================================================\n",
    "def ollama_run(prompt: str, model: str = \"dolphin-phi:2.7b\") -> str:\n",
    "    \"\"\"\n",
    "    Run a prompt against Ollama model and return text response.\n",
    "    Requires `ollama` to be running locally.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", model],\n",
    "            input=prompt.encode(\"utf-8\"),\n",
    "            capture_output=True,\n",
    "            check=True\n",
    "        )\n",
    "        return result.stdout.decode(\"utf-8\").strip()\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logging.error(f\"Ollama call failed: {e.stderr.decode('utf-8')}\")\n",
    "        return \"\"\n",
    "\n",
    "# ==================================================\n",
    "# 1. CSV Q&A WITH OLLAMA\n",
    "# ==================================================\n",
    "def ask_csv_question(csv_path: str, question: str) -> str:\n",
    "    \"\"\"\n",
    "    Ask Dolphin-phi a SQL-like query about a CSV.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    csv_text = df.head(200).to_csv(index=False)  # limit rows for context\n",
    "    prompt = f\"\"\"\n",
    "You are a trading data analyst.\n",
    "\n",
    "Here is a CSV (first 200 rows shown):\n",
    "{csv_text}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer concisely and clearly. If numeric filtering is needed, \n",
    "show the relevant rows as JSON.\n",
    "\"\"\"\n",
    "    return ollama_run(prompt)\n",
    "\n",
    "# ==================================================\n",
    "# 2. CROSSOVER RANKING WITH FUNDAMENTALS\n",
    "# ==================================================\n",
    "def rank_crossovers(crossover_df: pd.DataFrame, fundamentals_df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Rank crossovers using fundamentals context.\n",
    "    Returns structured JSON output.\n",
    "    \"\"\"\n",
    "    crossover_text = crossover_df.to_csv(index=False)\n",
    "    fundamentals_text = fundamentals_df.to_csv(index=False)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a financial analyst. \n",
    "\n",
    "Crossover events:\n",
    "{crossover_text}\n",
    "\n",
    "Fundamentals:\n",
    "{fundamentals_text}\n",
    "\n",
    "Task:\n",
    "- Rank the TOP 5 crossover events by strength.\n",
    "- Assign each a numeric strength score (1–10).\n",
    "- Explain briefly in 1–2 sentences why, referencing fundamentals.\n",
    "\n",
    "Return the output as a JSON array with fields:\n",
    "[{{\"date\": \"...\", \"signal\": \"...\", \"score\": 8, \"reason\": \"...\"}}]\n",
    "\"\"\"\n",
    "    return ollama_run(prompt)\n",
    "\n",
    "# ==================================================\n",
    "# 3. DEMO USAGE\n",
    "# ==================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Example CSV query\n",
    "    answer = ask_csv_question(\n",
    "        \"AAPL_technical_analysis.csv\",\n",
    "        \"Find EMA crossovers where MACD histogram was positive within 5 days.\"\n",
    "    )\n",
    "    print(\"\\nCSV Q&A Answer:\\n\", answer)\n",
    "\n",
    "    # Example crossover ranking\n",
    "    try:\n",
    "        crossovers = pd.read_csv(\"master_crossovers.csv\")\n",
    "        fundamentals = pd.read_csv(\"AAPL_key_fundamentals.csv\")\n",
    "        ranked = rank_crossovers(crossovers, fundamentals)\n",
    "        print(\"\\nRanked Crossovers:\\n\", ranked)\n",
    "    except FileNotFoundError:\n",
    "        print(\"CSV files not found — run your crossover detection script first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92e446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(61879) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV Q&A Answer:\n",
      " ], [\n",
      "    [0.1 for i in range(len(numbers))], [0.2 for i in range(len(numbers))],\n",
      "]], 'json')\n",
      "\n",
      "\n",
      "# Create an empty list called 'results' that will store the outputted data:\n",
      "results = []\n",
      "\n",
      "# Iterate through all three lists:\n",
      "for index, value in enumerate(list_1):\n",
      "    # If the length of values are different then return a non list-like object.\n",
      "    if len(list_2[index]) != len(list_3[index]):\n",
      "        return \"Error, The lengths of the lists are not equal.\"\n",
      "    # Add the current value to the 'results' list:\n",
      "    results.append((list_1[index][0], list_2[index][0], list_3[index][0]))\n",
      "\n",
      "    # Return the results:\n",
      "    return results\n",
      "CSV files not found — run your crossover detection script first.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# ==================================================\n",
    "# OLLAMA HELPER\n",
    "# ==================================================\n",
    "def ollama_run(prompt: str, model: str = \"dolphin-phi:2.7b\") -> str:\n",
    "    \"\"\"\n",
    "    Run a prompt against Ollama model and return text response.\n",
    "    \"\"\"\n",
    "    result = subprocess.run(\n",
    "        [\"ollama\", \"run\", model],\n",
    "        input=prompt.encode(\"utf-8\"),\n",
    "        capture_output=True,\n",
    "        check=True\n",
    "    )\n",
    "    return result.stdout.decode(\"utf-8\").strip()\n",
    "\n",
    "# ==================================================\n",
    "# STRICT CSV Q&A (uses pandas first, then LLM)\n",
    "# ==================================================\n",
    "def ask_csv_question(csv_path: str, question: str) -> str:\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # EXAMPLE HARDCODED query: EMA crossover + MACD histogram positive within 5 days\n",
    "    # You could expand this with a natural language -> pandas mapping later\n",
    "    if \"EMA\" in question and \"MACD\" in question:\n",
    "        if {\"EMA_12\", \"EMA_26\", \"MACD_Histogram\"}.issubset(df.columns):\n",
    "            crossover = (df[\"EMA_12\"] > df[\"EMA_26\"]) & (df[\"EMA_12\"].shift(1) <= df[\"EMA_26\"].shift(1))\n",
    "            df[\"crossover\"] = crossover\n",
    "            results = df[df[\"crossover\"]]\n",
    "\n",
    "            # check 5-day window for MACD positive\n",
    "            valid = []\n",
    "            for idx in results.index:\n",
    "                window = df.loc[idx: idx+5]\n",
    "                if (window[\"MACD_Histogram\"] > 0).any():\n",
    "                    valid.append(df.loc[idx])\n",
    "\n",
    "            if valid:\n",
    "                selected = pd.DataFrame(valid)\n",
    "                return selected.to_json(orient=\"records\", lines=True)\n",
    "\n",
    "    # fallback: just summarize with LLM\n",
    "    csv_text = df.head(50).to_csv(index=False)\n",
    "    prompt = f\"\"\"\n",
    "You are a CSV analysis assistant. \n",
    "Here is sample data:\n",
    "{csv_text}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "If possible, describe how to filter this dataset with pandas (not a generic essay).\n",
    "\"\"\"\n",
    "    return ollama_run(prompt)\n",
    "\n",
    "# ==================================================\n",
    "# CROSSOVER RANKING\n",
    "# ==================================================\n",
    "def rank_crossovers(crossover_df: pd.DataFrame, fundamentals_df: pd.DataFrame) -> str:\n",
    "    crossover_text = crossover_df.to_csv(index=False)\n",
    "    fundamentals_text = fundamentals_df.to_csv(index=False)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a financial analyst. \n",
    "\n",
    "Crossover events:\n",
    "{crossover_text}\n",
    "\n",
    "Fundamentals:\n",
    "{fundamentals_text}\n",
    "\n",
    "Task:\n",
    "- Rank the TOP 5 crossover events by strength.\n",
    "- Assign each a numeric strength score (1–10).\n",
    "- Explain briefly in 1–2 sentences why.\n",
    "\n",
    "Return as JSON:\n",
    "[{{\"date\": \"...\", \"signal\": \"...\", \"score\": 8, \"reason\": \"...\"}}]\n",
    "\"\"\"\n",
    "    return ollama_run(prompt)\n",
    "\n",
    "# ==================================================\n",
    "# DEMO\n",
    "# ==================================================\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Pandas does the filtering, LLM only summarizes if fallback\n",
    "        answer = ask_csv_question(\n",
    "            \"AAPL_technical_analysis.csv\",\n",
    "            \"Find EMA crossovers where MACD histogram was positive within 5 days.\"\n",
    "        )\n",
    "        print(\"\\nCSV Q&A Answer:\\n\", answer)\n",
    "\n",
    "        # Crossover ranking\n",
    "        crossovers = pd.read_csv(\"master_crossovers.csv\")\n",
    "        fundamentals = pd.read_csv(\"AAPL_key_fundamentals.csv\")\n",
    "        ranked = rank_crossovers(crossovers, fundamentals)\n",
    "        print(\"\\nRanked Crossovers:\\n\", ranked)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"CSV files not found — run your crossover detection script first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e98fb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yahoo_earnings_calendar\n",
      "  Downloading yahoo_earnings_calendar-0.6.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from yahoo_earnings_calendar) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from requests->yahoo_earnings_calendar) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from requests->yahoo_earnings_calendar) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from requests->yahoo_earnings_calendar) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages (from requests->yahoo_earnings_calendar) (2025.4.26)\n",
      "Downloading yahoo_earnings_calendar-0.6.0-py3-none-any.whl (7.9 kB)\n",
      "Installing collected packages: yahoo_earnings_calendar\n",
      "Successfully installed yahoo_earnings_calendar-0.6.0\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Invalid Symbol or Unavailable Earnings Date",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages/yahoo_earnings_calendar/scraper.py:54\u001b[0m, in \u001b[0;36mYahooEarningsCalendar.get_next_earnings_date\u001b[0;34m(self, symbol)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     page_data_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m page_data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdispatcher\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstores\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuoteSummaryStore\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalendarEvents\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearnings\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearningsDate\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages/yahoo_earnings_calendar/scraper.py:38\u001b[0m, in \u001b[0;36mYahooEarningsCalendar._get_data_dict\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     37\u001b[0m page_content \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode(encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m page_data_string \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage_content\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroot.App.main = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     40\u001b[0m page_data_string \u001b[38;5;241m=\u001b[39m page_data_string\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot.App.main = \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myahoo_earnings_calendar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YahooEarningsCalendar\n\u001b[1;32m      6\u001b[0m yec \u001b[38;5;241m=\u001b[39m YahooEarningsCalendar()\n\u001b[0;32m----> 7\u001b[0m future_ts \u001b[38;5;241m=\u001b[39m \u001b[43myec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next_earnings_date\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAAPL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# returns timestamp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m future_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mfromtimestamp(future_ts)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNext earnings:\u001b[39m\u001b[38;5;124m\"\u001b[39m, future_date)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/site-packages/yahoo_earnings_calendar/scraper.py:57\u001b[0m, in \u001b[0;36mYahooEarningsCalendar.get_next_earnings_date\u001b[0;34m(self, symbol)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m page_data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdispatcher\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstores\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuoteSummaryStore\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalendarEvents\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearnings\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearningsDate\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid Symbol or Unavailable Earnings Date\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Invalid Symbol or Unavailable Earnings Date"
     ]
    }
   ],
   "source": [
    "!pip install yahoo_earnings_calendar\n",
    "\n",
    "import datetime\n",
    "from yahoo_earnings_calendar import YahooEarningsCalendar\n",
    "\n",
    "yec = YahooEarningsCalendar()\n",
    "future_ts = yec.get_next_earnings_date(\"AAPL\")  # returns timestamp\n",
    "future_date = datetime.datetime.fromtimestamp(future_ts)\n",
    "print(\"Next earnings:\", future_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin-ai1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
