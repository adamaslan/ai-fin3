{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51bb6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16  CELL 1: Setup and Image Loading\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "# Initialize predictor with downloaded checkpoint\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Use the locally downloaded checkpoint\n",
    "checkpoint_path = \"./checkpoints/sam2.1_hiera_tiny.pt\"\n",
    "\n",
    "try:\n",
    "    # Load from local checkpoint instead of from_pretrained\n",
    "    from sam2.build_sam import build_sam2\n",
    "    from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "    \n",
    "    # Build SAM2 model from checkpoint\n",
    "    sam2_model = build_sam2(\"sam2.1_hiera_t.yaml\", checkpoint_path, device=device)\n",
    "    predictor = SAM2ImagePredictor(sam2_model)\n",
    "    print(\"✓ SAM2 predictor loaded successfully from local checkpoint\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading predictor from checkpoint: {e}\")\n",
    "    # Fallback to from_pretrained if available\n",
    "    try:\n",
    "        predictor = SAM2ImagePredictor.from_pretrained(\"facebook/sam2.1-hiera-tiny\")\n",
    "        print(\"✓ SAM2 predictor loaded successfully (fallback)\")\n",
    "    except Exception as e2:\n",
    "        print(f\"✗ Fallback also failed: {e2}\")\n",
    "        predictor = None\n",
    "\n",
    "# Load and display image\n",
    "image_path = \"/Users/adamaslan/code/ai-fin-opt2/ai-fin3/AAPL_band_anomalies_1-hour.png\"\n",
    "\n",
    "try:\n",
    "    input_image_pil = Image.open(image_path).convert(\"RGB\")\n",
    "    input_image_np = np.array(input_image_pil)\n",
    "    print(f\"✓ Image loaded: {image_path}\")\n",
    "    print(f\"Image dimensions: {input_image_np.shape}\")\n",
    "    \n",
    "    # Display the image\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(input_image_pil)\n",
    "    plt.title(\"Original Financial Chart - Click coordinates for segmentation\")\n",
    "    plt.axis('on')  # Keep axis to see coordinates\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading image: {e}\")\n",
    "    input_image_pil = None\n",
    "    input_image_np = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff1205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 from huggingface_hub import hf_hub_download\n",
    "\n",
    "checkpoint_path = hf_hub_download(\n",
    "    repo_id=\"facebook/sam2.1-hiera-tiny\",\n",
    "    filename=\"sam2.1_hiera_tiny.pt\",\n",
    "    local_dir=\"./checkpoints\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b1943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17\n",
    "f predictor:\n",
    "    # 1. Load your image\n",
    "    # Replace with the actual path to one of your PNG files\n",
    "    image_path = \"/Users/adamaslan/code/ai-fin-opt2/ai-fin3/AAPL_band_anomalies_1-hour.png\" \n",
    "    try:\n",
    "        input_image_pil = Image.open(image_path).convert(\"RGB\")\n",
    "        print(f\"Successfully loaded image: {image_path}\")\n",
    "        \n",
    "        # Convert PIL Image to a NumPy array if needed by set_image, or pass PIL image directly\n",
    "        # predictor.set_image usually expects a PyTorch tensor in CHW format (Channels, Height, Width)\n",
    "        # or sometimes a BGR numpy array. Check the specific requirements of SAM2ImagePredictor.set_image.\n",
    "        # For now, let's assume it can handle a PIL image or we'll adapt it.\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at {image_path}\")\n",
    "        input_image_pil = None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {e}\")\n",
    "        input_image_pil = None\n",
    "\n",
    "    if input_image_pil:\n",
    "        with torch.inference_mode(), torch.autocast(device, dtype=torch.bfloat16 if device != 'cpu' else torch.float32):\n",
    "            # 2. Set the image in the predictor\n",
    "            # This might involve preprocessing the PIL image to the format expected by the model\n",
    "            # (e.g., converting to tensor, normalizing, etc.)\n",
    "            # The exact preprocessing depends on the SAM2ImagePredictor implementation details.\n",
    "            # For simplicity, we'll assume set_image can handle a PIL image or a basic numpy array.\n",
    "            # You may need to consult the SAM2 documentation for precise input format.\n",
    "            try:\n",
    "                # Example: Convert PIL to NumPy array (H, W, C)\n",
    "                # input_image_np = np.array(input_image_pil)\n",
    "                # predictor.set_image(input_image_np) \n",
    "                \n",
    "                # The `set_image` method in the official SAM/SAM2 examples often takes a BGR numpy array.\n",
    "                # Let's try to provide it in a way that's commonly used, but you might need to adjust.\n",
    "                bgr_image = np.array(input_image_pil)[:, :, ::-1] # RGB to BGR\n",
    "                predictor.set_image(bgr_image)\n",
    "                print(\"Image set in predictor.\")\n",
    "\n",
    "                # 3. Define your input prompts (THIS IS THE CRITICAL PART YOU NEED TO CUSTOMIZE)\n",
    "                # Prompts can be points, boxes, or masks.\n",
    "                # For Bollinger Band squeezes, you might use bounding boxes.\n",
    "                # Example: A bounding box [x_min, y_min, x_max, y_max]\n",
    "                # You'll need to determine these coordinates by inspecting your image.\n",
    "                # input_prompts = {\n",
    "                #     \"point_coords\": None, # e.g., [[[x1, y1], [x2, y2]]]\n",
    "                #     \"point_labels\": None, # e.g., [[1, 0]] (1 for foreground, 0 for background)\n",
    "                #     \"box\": np.array([[100, 200, 300, 250]]), # Example: [[x_min, y_min, x_max, y_max]]\n",
    "                #     \"mask_input\": None\n",
    "                # }\n",
    "                \n",
    "                # Placeholder: You MUST define appropriate prompts for your image and task.\n",
    "                # For example, to segment a squeeze visually identified at coordinates (x1,y1) to (x2,y2)\n",
    "                # on the 'AAPL_band_anomalies_1-hour.png' image:\n",
    "                # You would need to find these pixel coordinates by looking at the image.\n",
    "                # Let's assume a hypothetical squeeze box for demonstration:\n",
    "                # This is an EXAMPLE, replace with actual coordinates from your image inspection.\n",
    "                squeeze_box_example = np.array([[50, 100, 200, 150]]) # [xmin, ymin, xmax, ymax]\n",
    "                \n",
    "                input_prompts = {\"box\": squeeze_box_example}\n",
    "                print(f\"Using example prompt box: {squeeze_box_example}\")\n",
    "\n",
    "                # 4. Make the prediction\n",
    "                masks, scores, logits = predictor.predict(\n",
    "                    point_coords=input_prompts.get(\"point_coords\"),\n",
    "                    point_labels=input_prompts.get(\"point_labels\"),\n",
    "                    box=input_prompts.get(\"box\"),\n",
    "                    mask_input=input_prompts.get(\"mask_input\"),\n",
    "                    multimask_output=True # Get multiple masks if available\n",
    "                )\n",
    "                \n",
    "                print(f\"Prediction complete. Number of masks generated: {len(masks)}\")\n",
    "                # masks is a NumPy array of shape (num_masks, height, width)\n",
    "                # scores is a NumPy array of shape (num_masks,)\n",
    "\n",
    "                # You can then visualize these masks, e.g., using matplotlib\n",
    "                # import matplotlib.pyplot as plt\n",
    "                # for i, mask in enumerate(masks):\n",
    "                #     plt.figure()\n",
    "                #     plt.imshow(input_image_pil)\n",
    "                #     plt.imshow(mask, alpha=0.5, cmap='jet')\n",
    "                #     plt.title(f\"Mask {i+1}, Score: {scores[i]:.2f}\")\n",
    "                #     plt.axis('off')\n",
    "                # plt.show()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error during prediction: {e}\")\n",
    "else:\n",
    "    print(\"Predictor not loaded. Cannot proceed with image processing and prediction.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
